{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .appName('my-cool-app') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import explode, col, udf, mean as _mean, stddev as _stddev, log, log10\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.functions import lit\n",
    "sc = SparkContext()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c7bc98a6-96a0-4899-9b1b-2686b17f1e7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, StandardScaler, VectorAssembler, VectorSlicer, PCA\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.ml.clustering import KMeans\n",
    "import re\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "02385597-27bc-418a-8725-873b1b3f2022",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Functions for Feature Engineering\n",
    "def encode_cat_features(df, cat_features):\n",
    "\n",
    "  indexed_cols = [''.join([col_name, '_indexed']) for col_name in cat_features]\n",
    "  encoded_cols = [''.join([col_name, '_encoded']) for col_name in cat_features]\n",
    "  string_indexers = [StringIndexer(inputCol=cat_features[i], outputCol=indexed_cols[i]) for i in range(len(cat_features))]\n",
    "    \n",
    "  encoder = OneHotEncoder(inputCols=indexed_cols, outputCols=encoded_cols)\n",
    "  \n",
    "  pipline = Pipeline(stages=string_indexers + [encoder])\n",
    "  \n",
    "  encoded_df = pipline.fit(df).transform(df)\n",
    "  encoded_df = encoded_df.drop(*indexed_cols + cat_features)\n",
    "\n",
    "  return encoded_df\n",
    "\n",
    "def normalize_features(df, cols, normalizer, output_cols, if_drop=True):\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  normalizer_lst = []\n",
    "  vectorized_cols = []\n",
    "  vector_assembers = []\n",
    "  \n",
    "  if isinstance(cols, list):\n",
    "    cols = {'cols': cols}\n",
    "  \n",
    "  if isinstance(output_cols, str):\n",
    "    output_cols = {'cols': output_cols}\n",
    "  \n",
    "  for k, v in cols.items():\n",
    "    \n",
    "    temp_normalizer = normalizer.copy()\n",
    "    vectorized_col = ''.join([output_cols[k], '_v'])\n",
    "    vector_assember = VectorAssembler(inputCols=v, outputCol=vectorized_col)\n",
    "    \n",
    "    temp_normalizer.setInputCol(vectorized_col)\n",
    "    temp_normalizer.setOutputCol(output_cols[k])\n",
    "    \n",
    "    normalizer_lst.append(temp_normalizer)\n",
    "    vectorized_cols.append(vectorized_col)\n",
    "    vector_assembers.append(vector_assember)\n",
    "  \n",
    "  pipline = Pipeline(stages=vector_assembers + normalizer_lst)\n",
    "  normalized_df = pipline.fit(df).transform(df).drop(*vectorized_cols)\n",
    "  \n",
    "  if if_drop:\n",
    "    \n",
    "    for k, v in cols.items():\n",
    "      \n",
    "      normalized_df = normalized_df.drop(v)\n",
    "  \n",
    "  return normalized_df\n",
    "\n",
    "def add_pca_features(df, g_cols, c_cols, k=40):\n",
    "  \n",
    "  ## normalize g-col and c-col\n",
    "  std_scaler = StandardScaler(withMean=True)\n",
    "  \n",
    "  input_cols = {\n",
    "    'g_cols': g_cols, \n",
    "    'c_cols': c_cols}\n",
    "  \n",
    "  output_cols = {\n",
    "    'g_cols': 'g_normalized', \n",
    "    'c_cols': 'c_normalized'}\n",
    "  \n",
    "  normalized_df = normalize_features(df, input_cols, std_scaler, output_cols, if_drop=False)\n",
    "  \n",
    "  ## perform PCA on g-cols and c-cols\n",
    "  g_col_pca = PCA(k=k, inputCol='g_normalized', outputCol='g_col_pca')\n",
    "  c_col_pca = PCA(k=k, inputCol='c_normalized', outputCol='c_col_pca')\n",
    "  \n",
    "  pipeline = Pipeline(stages=[g_col_pca, c_col_pca])\n",
    "  pca_df = pipeline.fit(normalized_df).transform(normalized_df)\n",
    "  \n",
    "  return pca_df\n",
    "  \n",
    "def add_stats_features(df, g_cols, c_cols):\n",
    "  \n",
    "  @udf('double')\n",
    "  def cols_sum(*lst):\n",
    "\n",
    "    return sum(lst)\n",
    "\n",
    "  @udf('double')\n",
    "  def cols_mean(*lst):\n",
    "\n",
    "    n = len(lst)\n",
    "    s = sum(lst)\n",
    "\n",
    "    return s / n\n",
    "\n",
    "  @udf('double')\n",
    "  def cols_var(*lst):\n",
    "\n",
    "    n = len(lst)\n",
    "    s = sum(lst) / n\n",
    "    total = 0\n",
    "\n",
    "    for x in lst:\n",
    "\n",
    "      total += (x - s)**2 \n",
    "\n",
    "    return total / n\n",
    "  \n",
    "  @udf('double')\n",
    "  def cols_min(*lst):\n",
    "    \n",
    "    return min(lst)\n",
    "  \n",
    "  @udf('double')\n",
    "  def cols_max(*lst):\n",
    "    \n",
    "    return max(lst)\n",
    "  \n",
    "  stats_dict = {\n",
    "    'min_stats': cols_min,\n",
    "    'max_stats': cols_max,\n",
    "    'var_stats': cols_var,\n",
    "    'mean_stats': cols_mean,\n",
    "    'sum_stats': cols_sum\n",
    "  }\n",
    "  \n",
    "  for name, func in stats_dict.items():\n",
    "    \n",
    "    df = df.withColumn(''.join(['g_cols_', name]), func(*[col(g_col) for g_col in g_cols]))\n",
    "    df = df.withColumn(''.join(['c_cols_', name]), func(*[col(c_col) for c_col in c_cols]))\n",
    "  \n",
    "  return df\n",
    "\n",
    "def add_kmeans_features(df, g_cols, c_cols, k=2, num_iter=10):\n",
    "  \n",
    "  kmeans_g = KMeans(k=k, featuresCol=g_cols, predictionCol='g_col_k_mean', seed=16)\n",
    "  kmeans_c = KMeans(k=k, featuresCol=c_cols, predictionCol='c_col_k_mean', seed=16)\n",
    "  \n",
    "  kmeans_df = kmeans_g.fit(df).transform(df)\n",
    "  kmeans_df = kmeans_c.fit(kmeans_df).transform(kmeans_df)\n",
    "  \n",
    "  return kmeans_df\n",
    "\n",
    "def feature_engineering(df, num_cluster=2, num_comp=40, num_iter=10):\n",
    "  \n",
    "  ## get g-col and c-col\n",
    "  g_cols = list(filter(lambda v: re.match('g-.+', v), df.columns))\n",
    "  c_cols = list(filter(lambda v: re.match('c-.+', v), df.columns))\n",
    "  \n",
    "  ## PCA\n",
    "  pca_df = add_pca_features(df, g_cols, c_cols, num_comp)\n",
    "\n",
    "  ## stats features on g and c cols\n",
    "  stats_df = add_stats_features(pca_df, g_cols, c_cols)\n",
    "  \n",
    "  ## add k-means features\n",
    "  kmeans_df = add_kmeans_features(stats_df, g_cols='g_normalized', c_cols='c_normalized', k=num_cluster, num_iter=num_iter)\n",
    "  \n",
    "  return kmeans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Multilabel Classifier\n",
    "class MultiLabelClassifier:\n",
    "    \n",
    "    def __init__(self, clf, labels, feature_col,  \n",
    "                 hyperparameters={}, \n",
    "                 predict_col=['probability','prediction'],\n",
    "                 method=lambda prob_col, pred_col: float(pred_col if len(prob_col) == 1 else prob_col[1])):\n",
    "        '''\n",
    "        Initialize a multilabelclassifier\n",
    "        clf: the model to use\n",
    "        labels: a list of labels to predict\n",
    "        feature_col: the feature column\n",
    "        predict_col: the prediction column where the prediction is located\n",
    "        hyperparameters: all optional hyperparameters that can tune\n",
    "        method: a method of how to get the final prediction for one class\n",
    "        '''\n",
    "        self.clf = clf\n",
    "        self.labels = labels\n",
    "        self.feature_col = feature_col\n",
    "        self.predict_col = predict_col\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.method = method\n",
    "        self._trained_clfs = []\n",
    "\n",
    "    def fit(self, train):\n",
    "        self._trained_clfs = [self.clf(labelCol=label, featuresCol=self.feature_col, **self.hyperparameters)\n",
    "                              .fit(train) \n",
    "                              for label in tqdm(self.labels)]\n",
    "        return self\n",
    "\n",
    "    def transform(self, x_test):\n",
    "        get_predict = udf(self.method,FloatType())\n",
    "        select_cols = [self.feature_col, 'sig_id'] # need to change if have time\n",
    "        res = x_test.select(*select_cols)\n",
    "        for i, clf in tqdm(enumerate(self._trained_clfs)):\n",
    "            res = clf.transform(res)\n",
    "            res = res.withColumn(self.labels[i], get_predict(*self.predict_col))\n",
    "            select_cols.append(self.labels[i])\n",
    "            res = res.select(*select_cols)\n",
    "        res = res.select(*select_cols[1:])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def score(y, y_hat, join_id):\n",
    "    import math\n",
    "    target_cols = y.drop(join_id).columns\n",
    "    @udf('double')\n",
    "    def loss(t, p):\n",
    "        cut = 10**(-15)\n",
    "        p = max(min(p, 1-cut),cut)\n",
    "        return t * math.log(p) + (1 - t) * math.log(1 - p)\n",
    "    #rename columns\n",
    "    for c in target_cols:\n",
    "        y_hat = y_hat.withColumnRenamed(c, c+'_y_hat')\n",
    "    #inner join table on join_id\n",
    "    df = y_hat.join(y, join_id, 'inner')\n",
    "    name = target_cols[0]\n",
    "    df = df.withColumn('log_loss', loss(name, name+'_y_hat'))\n",
    "    for name in target_cols[1:]:\n",
    "        df = df.withColumn('log_loss', col('log_loss')+loss(name, name+'_y_hat'))\n",
    "    df = df.withColumn('log_loss', col('log_loss')/len(target_cols))\n",
    "    res = df.select((-_mean(col('log_loss'))).alias('score'))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0722f2bf-4663-4034-8ad2-28be805d8c33",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#file_path = '/FileStore/tables/'\n",
    "file_path = './'\n",
    "sample_id = 'sig_id'\n",
    "train_df = spark.read.csv(file_path+'train_features.csv', header=True, inferSchema=True)\n",
    "target_df = spark.read.csv(file_path+'train_targets_scored.csv', header=True, inferSchema=True)\n",
    "train_drug_df = spark.read.csv(file_path+'train_drug.csv', header=True, inferSchema=True)\n",
    "target_nonscored_df = spark.read.csv(file_path+'train_targets_nonscored.csv', header=True, inferSchema=True)\n",
    "test_df = spark.read.csv(file_path+'test_features.csv', header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cdf91bbe-590f-45f7-8fcd-29af4fd9d553",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[sig_id: string, cp_type: string, cp_time: int, cp_dose: string, g-0: double, g-1: double, g-2: double, g-3: double, g-4: double, g-5: double, g-6: double, g-7: double, g-8: double, g-9: double, g-10: double, g-11: double, g-12: double, g-13: double, g-14: double, g-15: double, g-16: double, g-17: double, g-18: double, g-19: double, g-20: double, g-21: double, g-22: double, g-23: double, g-24: double, g-25: double, g-26: double, g-27: double, g-28: double, g-29: double, g-30: double, g-31: double, g-32: double, g-33: double, g-34: double, g-35: double, g-36: double, g-37: double, g-38: double, g-39: double, g-40: double, g-41: double, g-42: double, g-43: double, g-44: double, g-45: double, g-46: double, g-47: double, g-48: double, g-49: double, g-50: double, g-51: double, g-52: double, g-53: double, g-54: double, g-55: double, g-56: double, g-57: double, g-58: double, g-59: double, g-60: double, g-61: double, g-62: double, g-63: double, g-64: double, g-65: double, g-66: double, g-67: double, g-68: double, g-69: double, g-70: double, g-71: double, g-72: double, g-73: double, g-74: double, g-75: double, g-76: double, g-77: double, g-78: double, g-79: double, g-80: double, g-81: double, g-82: double, g-83: double, g-84: double, g-85: double, g-86: double, g-87: double, g-88: double, g-89: double, g-90: double, g-91: double, g-92: double, g-93: double, g-94: double, g-95: double, g-96: double, g-97: double, g-98: double, g-99: double, g-100: double, g-101: double, g-102: double, g-103: double, g-104: double, g-105: double, g-106: double, g-107: double, g-108: double, g-109: double, g-110: double, g-111: double, g-112: double, g-113: double, g-114: double, g-115: double, g-116: double, g-117: double, g-118: double, g-119: double, g-120: double, g-121: double, g-122: double, g-123: double, g-124: double, g-125: double, g-126: double, g-127: double, g-128: double, g-129: double, g-130: double, g-131: double, g-132: double, g-133: double, g-134: double, g-135: double, g-136: double, g-137: double, g-138: double, g-139: double, g-140: double, g-141: double, g-142: double, g-143: double, g-144: double, g-145: double, g-146: double, g-147: double, g-148: double, g-149: double, g-150: double, g-151: double, g-152: double, g-153: double, g-154: double, g-155: double, g-156: double, g-157: double, g-158: double, g-159: double, g-160: double, g-161: double, g-162: double, g-163: double, g-164: double, g-165: double, g-166: double, g-167: double, g-168: double, g-169: double, g-170: double, g-171: double, g-172: double, g-173: double, g-174: double, g-175: double, g-176: double, g-177: double, g-178: double, g-179: double, g-180: double, g-181: double, g-182: double, g-183: double, g-184: double, g-185: double, g-186: double, g-187: double, g-188: double, g-189: double, g-190: double, g-191: double, g-192: double, g-193: double, g-194: double, g-195: double, g-196: double, g-197: double, g-198: double, g-199: double, g-200: double, g-201: double, g-202: double, g-203: double, g-204: double, g-205: double, g-206: double, g-207: double, g-208: double, g-209: double, g-210: double, g-211: double, g-212: double, g-213: double, g-214: double, g-215: double, g-216: double, g-217: double, g-218: double, g-219: double, g-220: double, g-221: double, g-222: double, g-223: double, g-224: double, g-225: double, g-226: double, g-227: double, g-228: double, g-229: double, g-230: double, g-231: double, g-232: double, g-233: double, g-234: double, g-235: double, g-236: double, g-237: double, g-238: double, g-239: double, g-240: double, g-241: double, g-242: double, g-243: double, g-244: double, g-245: double, g-246: double, g-247: double, g-248: double, g-249: double, g-250: double, g-251: double, g-252: double, g-253: double, g-254: double, g-255: double, g-256: double, g-257: double, g-258: double, g-259: double, g-260: double, g-261: double, g-262: double, g-263: double, g-264: double, g-265: double, g-266: double, g-267: double, g-268: double, g-269: double, g-270: double, g-271: double, g-272: double, g-273: double, g-274: double, g-275: double, g-276: double, g-277: double, g-278: double, g-279: double, g-280: double, g-281: double, g-282: double, g-283: double, g-284: double, g-285: double, g-286: double, g-287: double, g-288: double, g-289: double, g-290: double, g-291: double, g-292: double, g-293: double, g-294: double, g-295: double, g-296: double, g-297: double, g-298: double, g-299: double, g-300: double, g-301: double, g-302: double, g-303: double, g-304: double, g-305: double, g-306: double, g-307: double, g-308: double, g-309: double, g-310: double, g-311: double, g-312: double, g-313: double, g-314: double, g-315: double, g-316: double, g-317: double, g-318: double, g-319: double, g-320: double, g-321: double, g-322: double, g-323: double, g-324: double, g-325: double, g-326: double, g-327: double, g-328: double, g-329: double, g-330: double, g-331: double, g-332: double, g-333: double, g-334: double, g-335: double, g-336: double, g-337: double, g-338: double, g-339: double, g-340: double, g-341: double, g-342: double, g-343: double, g-344: double, g-345: double, g-346: double, g-347: double, g-348: double, g-349: double, g-350: double, g-351: double, g-352: double, g-353: double, g-354: double, g-355: double, g-356: double, g-357: double, g-358: double, g-359: double, g-360: double, g-361: double, g-362: double, g-363: double, g-364: double, g-365: double, g-366: double, g-367: double, g-368: double, g-369: double, g-370: double, g-371: double, g-372: double, g-373: double, g-374: double, g-375: double, g-376: double, g-377: double, g-378: double, g-379: double, g-380: double, g-381: double, g-382: double, g-383: double, g-384: double, g-385: double, g-386: double, g-387: double, g-388: double, g-389: double, g-390: double, g-391: double, g-392: double, g-393: double, g-394: double, g-395: double, g-396: double, g-397: double, g-398: double, g-399: double, g-400: double, g-401: double, g-402: double, g-403: double, g-404: double, g-405: double, g-406: double, g-407: double, g-408: double, g-409: double, g-410: double, g-411: double, g-412: double, g-413: double, g-414: double, g-415: double, g-416: double, g-417: double, g-418: double, g-419: double, g-420: double, g-421: double, g-422: double, g-423: double, g-424: double, g-425: double, g-426: double, g-427: double, g-428: double, g-429: double, g-430: double, g-431: double, g-432: double, g-433: double, g-434: double, g-435: double, g-436: double, g-437: double, g-438: double, g-439: double, g-440: double, g-441: double, g-442: double, g-443: double, g-444: double, g-445: double, g-446: double, g-447: double, g-448: double, g-449: double, g-450: double, g-451: double, g-452: double, g-453: double, g-454: double, g-455: double, g-456: double, g-457: double, g-458: double, g-459: double, g-460: double, g-461: double, g-462: double, g-463: double, g-464: double, g-465: double, g-466: double, g-467: double, g-468: double, g-469: double, g-470: double, g-471: double, g-472: double, g-473: double, g-474: double, g-475: double, g-476: double, g-477: double, g-478: double, g-479: double, g-480: double, g-481: double, g-482: double, g-483: double, g-484: double, g-485: double, g-486: double, g-487: double, g-488: double, g-489: double, g-490: double, g-491: double, g-492: double, g-493: double, g-494: double, g-495: double, g-496: double, g-497: double, g-498: double, g-499: double, g-500: double, g-501: double, g-502: double, g-503: double, g-504: double, g-505: double, g-506: double, g-507: double, g-508: double, g-509: double, g-510: double, g-511: double, g-512: double, g-513: double, g-514: double, g-515: double, g-516: double, g-517: double, g-518: double, g-519: double, g-520: double, g-521: double, g-522: double, g-523: double, g-524: double, g-525: double, g-526: double, g-527: double, g-528: double, g-529: double, g-530: double, g-531: double, g-532: double, g-533: double, g-534: double, g-535: double, g-536: double, g-537: double, g-538: double, g-539: double, g-540: double, g-541: double, g-542: double, g-543: double, g-544: double, g-545: double, g-546: double, g-547: double, g-548: double, g-549: double, g-550: double, g-551: double, g-552: double, g-553: double, g-554: double, g-555: double, g-556: double, g-557: double, g-558: double, g-559: double, g-560: double, g-561: double, g-562: double, g-563: double, g-564: double, g-565: double, g-566: double, g-567: double, g-568: double, g-569: double, g-570: double, g-571: double, g-572: double, g-573: double, g-574: double, g-575: double, g-576: double, g-577: double, g-578: double, g-579: double, g-580: double, g-581: double, g-582: double, g-583: double, g-584: double, g-585: double, g-586: double, g-587: double, g-588: double, g-589: double, g-590: double, g-591: double, g-592: double, g-593: double, g-594: double, g-595: double, g-596: double, g-597: double, g-598: double, g-599: double, g-600: double, g-601: double, g-602: double, g-603: double, g-604: double, g-605: double, g-606: double, g-607: double, g-608: double, g-609: double, g-610: double, g-611: double, g-612: double, g-613: double, g-614: double, g-615: double, g-616: double, g-617: double, g-618: double, g-619: double, g-620: double, g-621: double, g-622: double, g-623: double, g-624: double, g-625: double, g-626: double, g-627: double, g-628: double, g-629: double, g-630: double, g-631: double, g-632: double, g-633: double, g-634: double, g-635: double, g-636: double, g-637: double, g-638: double, g-639: double, g-640: double, g-641: double, g-642: double, g-643: double, g-644: double, g-645: double, g-646: double, g-647: double, g-648: double, g-649: double, g-650: double, g-651: double, g-652: double, g-653: double, g-654: double, g-655: double, g-656: double, g-657: double, g-658: double, g-659: double, g-660: double, g-661: double, g-662: double, g-663: double, g-664: double, g-665: double, g-666: double, g-667: double, g-668: double, g-669: double, g-670: double, g-671: double, g-672: double, g-673: double, g-674: double, g-675: double, g-676: double, g-677: double, g-678: double, g-679: double, g-680: double, g-681: double, g-682: double, g-683: double, g-684: double, g-685: double, g-686: double, g-687: double, g-688: double, g-689: double, g-690: double, g-691: double, g-692: double, g-693: double, g-694: double, g-695: double, g-696: double, g-697: double, g-698: double, g-699: double, g-700: double, g-701: double, g-702: double, g-703: double, g-704: double, g-705: double, g-706: double, g-707: double, g-708: double, g-709: double, g-710: double, g-711: double, g-712: double, g-713: double, g-714: double, g-715: double, g-716: double, g-717: double, g-718: double, g-719: double, g-720: double, g-721: double, g-722: double, g-723: double, g-724: double, g-725: double, g-726: double, g-727: double, g-728: double, g-729: double, g-730: double, g-731: double, g-732: double, g-733: double, g-734: double, g-735: double, g-736: double, g-737: double, g-738: double, g-739: double, g-740: double, g-741: double, g-742: double, g-743: double, g-744: double, g-745: double, g-746: double, g-747: double, g-748: double, g-749: double, g-750: double, g-751: double, g-752: double, g-753: double, g-754: double, g-755: double, g-756: double, g-757: double, g-758: double, g-759: double, g-760: double, g-761: double, g-762: double, g-763: double, g-764: double, g-765: double, g-766: double, g-767: double, g-768: double, g-769: double, g-770: double, g-771: double, c-0: double, c-1: double, c-2: double, c-3: double, c-4: double, c-5: double, c-6: double, c-7: double, c-8: double, c-9: double, c-10: double, c-11: double, c-12: double, c-13: double, c-14: double, c-15: double, c-16: double, c-17: double, c-18: double, c-19: double, c-20: double, c-21: double, c-22: double, c-23: double, c-24: double, c-25: double, c-26: double, c-27: double, c-28: double, c-29: double, c-30: double, c-31: double, c-32: double, c-33: double, c-34: double, c-35: double, c-36: double, c-37: double, c-38: double, c-39: double, c-40: double, c-41: double, c-42: double, c-43: double, c-44: double, c-45: double, c-46: double, c-47: double, c-48: double, c-49: double, c-50: double, c-51: double, c-52: double, c-53: double, c-54: double, c-55: double, c-56: double, c-57: double, c-58: double, c-59: double, c-60: double, c-61: double, c-62: double, c-63: double, c-64: double, c-65: double, c-66: double, c-67: double, c-68: double, c-69: double, c-70: double, c-71: double, c-72: double, c-73: double, c-74: double, c-75: double, c-76: double, c-77: double, c-78: double, c-79: double, c-80: double, c-81: double, c-82: double, c-83: double, c-84: double, c-85: double, c-86: double, c-87: double, c-88: double, c-89: double, c-90: double, c-91: double, c-92: double, c-93: double, c-94: double, c-95: double, c-96: double, c-97: double, c-98: double, c-99: double]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.cache()\n",
    "target_df.cache()\n",
    "test_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d7a98442-7ce1-4a03-afeb-28cf20d9c28b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## add indicator column to both train and test so we can combine them later\n",
    "train_df = train_df.withColumn('is_test', lit(0))\n",
    "test_df = test_df.withColumn('is_test', lit(1))\n",
    "\n",
    "## Combine train and test df\n",
    "full_df = train_df.union(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "00beab73-8c18-4835-b783-bede27b844ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## encode features\n",
    "target_cols = ['cp_type', 'cp_dose']\n",
    "encoded_df = encode_cat_features(full_df, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "55343a7f-035e-4f85-903f-5db6e44f50e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## feature engineering\n",
    "fe_df = feature_engineering(encoded_df, num_comp=20, num_iter=5)\n",
    "\n",
    "## select all the feature columns\n",
    "\n",
    "pca_cols = list(filter(lambda v: re.match('.+_pca', v), fe_df.columns))\n",
    "stats_cols = list(filter(lambda v: re.match('.+_stats', v), fe_df.columns))\n",
    "k_means_cols = list(filter(lambda v: re.match('.+_k_mean', v), fe_df.columns))\n",
    "cat_cols = list(filter(lambda v: re.match('.+_encoded', v), fe_df.columns)) + ['cp_time']\n",
    "\n",
    "## stack them to a single feature vector\n",
    "vector_assember_train = VectorAssembler(inputCols=pca_cols + stats_cols + k_means_cols + cat_cols, outputCol='all_features')\n",
    "fe_df = vector_assember_train.transform(fe_df)\n",
    "\n",
    "## normalize all the features\n",
    "normalizer = StandardScaler(withMean=True)\n",
    "cols = ['all_features']\n",
    "output_cols = 'features'\n",
    "fe_df = normalize_features(fe_df, cols, normalizer, output_cols, if_drop=False)\n",
    "\n",
    "## split train, test df\n",
    "fe_train = fe_df.filter(fe_df['is_test'] == 0)\n",
    "final_test = fe_df.filter(fe_df['is_test'] == 1).select(['sig_id', 'features'])\n",
    "\n",
    "## join training target with training features\n",
    "labels = target_df.drop('sig_id').columns\n",
    "final_train = fe_train.join(target_df, ['sig_id']).select(*(['sig_id','features']+labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is just for test. you can delete this after optimize feature engineering\n",
    "\"\"\"\n",
    "\n",
    "# preprocess data\n",
    "train_feature_df = train_df.drop(*['cp_type', 'cp_time','cp_dose'])\n",
    "\n",
    "# assemble features\n",
    "assemble_cols = train_feature_df.drop(sample_id).columns\n",
    "vector_assember_train = VectorAssembler(inputCols=assemble_cols, outputCol='features')\n",
    "train_feature_df = vector_assember_train.transform(train_feature_df).select(sample_id, 'features')\n",
    "train_feature_df = train_feature_df.select(sample_id, 'features')\n",
    "\n",
    "# join features with all targets\n",
    "final_train = train_feature_df.join(target_df, sample_id, 'inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bdf7e32a-ca3a-4de7-b522-31f1137d676c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[sig_id: string, features: vector, 5-alpha_reductase_inhibitor: int, 11-beta-hsd1_inhibitor: int, acat_inhibitor: int, acetylcholine_receptor_agonist: int, acetylcholine_receptor_antagonist: int, acetylcholinesterase_inhibitor: int, adenosine_receptor_agonist: int, adenosine_receptor_antagonist: int, adenylyl_cyclase_activator: int, adrenergic_receptor_agonist: int, adrenergic_receptor_antagonist: int, akt_inhibitor: int, aldehyde_dehydrogenase_inhibitor: int, alk_inhibitor: int, ampk_activator: int, analgesic: int, androgen_receptor_agonist: int, androgen_receptor_antagonist: int, anesthetic_-_local: int, angiogenesis_inhibitor: int, angiotensin_receptor_antagonist: int, anti-inflammatory: int, antiarrhythmic: int, antibiotic: int, anticonvulsant: int, antifungal: int, antihistamine: int, antimalarial: int, antioxidant: int, antiprotozoal: int, antiviral: int, apoptosis_stimulant: int, aromatase_inhibitor: int, atm_kinase_inhibitor: int, atp-sensitive_potassium_channel_antagonist: int, atp_synthase_inhibitor: int, atpase_inhibitor: int, atr_kinase_inhibitor: int, aurora_kinase_inhibitor: int, autotaxin_inhibitor: int, bacterial_30s_ribosomal_subunit_inhibitor: int, bacterial_50s_ribosomal_subunit_inhibitor: int, bacterial_antifolate: int, bacterial_cell_wall_synthesis_inhibitor: int, bacterial_dna_gyrase_inhibitor: int, bacterial_dna_inhibitor: int, bacterial_membrane_integrity_inhibitor: int, bcl_inhibitor: int, bcr-abl_inhibitor: int, benzodiazepine_receptor_agonist: int, beta_amyloid_inhibitor: int, bromodomain_inhibitor: int, btk_inhibitor: int, calcineurin_inhibitor: int, calcium_channel_blocker: int, cannabinoid_receptor_agonist: int, cannabinoid_receptor_antagonist: int, carbonic_anhydrase_inhibitor: int, casein_kinase_inhibitor: int, caspase_activator: int, catechol_o_methyltransferase_inhibitor: int, cc_chemokine_receptor_antagonist: int, cck_receptor_antagonist: int, cdk_inhibitor: int, chelating_agent: int, chk_inhibitor: int, chloride_channel_blocker: int, cholesterol_inhibitor: int, cholinergic_receptor_antagonist: int, coagulation_factor_inhibitor: int, corticosteroid_agonist: int, cyclooxygenase_inhibitor: int, cytochrome_p450_inhibitor: int, dihydrofolate_reductase_inhibitor: int, dipeptidyl_peptidase_inhibitor: int, diuretic: int, dna_alkylating_agent: int, dna_inhibitor: int, dopamine_receptor_agonist: int, dopamine_receptor_antagonist: int, egfr_inhibitor: int, elastase_inhibitor: int, erbb2_inhibitor: int, estrogen_receptor_agonist: int, estrogen_receptor_antagonist: int, faah_inhibitor: int, farnesyltransferase_inhibitor: int, fatty_acid_receptor_agonist: int, fgfr_inhibitor: int, flt3_inhibitor: int, focal_adhesion_kinase_inhibitor: int, free_radical_scavenger: int, fungal_squalene_epoxidase_inhibitor: int, gaba_receptor_agonist: int, gaba_receptor_antagonist: int, gamma_secretase_inhibitor: int, glucocorticoid_receptor_agonist: int, glutamate_inhibitor: int, glutamate_receptor_agonist: int, glutamate_receptor_antagonist: int, gonadotropin_receptor_agonist: int, gsk_inhibitor: int, hcv_inhibitor: int, hdac_inhibitor: int, histamine_receptor_agonist: int, histamine_receptor_antagonist: int, histone_lysine_demethylase_inhibitor: int, histone_lysine_methyltransferase_inhibitor: int, hiv_inhibitor: int, hmgcr_inhibitor: int, hsp_inhibitor: int, igf-1_inhibitor: int, ikk_inhibitor: int, imidazoline_receptor_agonist: int, immunosuppressant: int, insulin_secretagogue: int, insulin_sensitizer: int, integrin_inhibitor: int, jak_inhibitor: int, kit_inhibitor: int, laxative: int, leukotriene_inhibitor: int, leukotriene_receptor_antagonist: int, lipase_inhibitor: int, lipoxygenase_inhibitor: int, lxr_agonist: int, mdm_inhibitor: int, mek_inhibitor: int, membrane_integrity_inhibitor: int, mineralocorticoid_receptor_antagonist: int, monoacylglycerol_lipase_inhibitor: int, monoamine_oxidase_inhibitor: int, monopolar_spindle_1_kinase_inhibitor: int, mtor_inhibitor: int, mucolytic_agent: int, neuropeptide_receptor_antagonist: int, nfkb_inhibitor: int, nicotinic_receptor_agonist: int, nitric_oxide_donor: int, nitric_oxide_production_inhibitor: int, nitric_oxide_synthase_inhibitor: int, norepinephrine_reuptake_inhibitor: int, nrf2_activator: int, opioid_receptor_agonist: int, opioid_receptor_antagonist: int, orexin_receptor_antagonist: int, p38_mapk_inhibitor: int, p-glycoprotein_inhibitor: int, parp_inhibitor: int, pdgfr_inhibitor: int, pdk_inhibitor: int, phosphodiesterase_inhibitor: int, phospholipase_inhibitor: int, pi3k_inhibitor: int, pkc_inhibitor: int, potassium_channel_activator: int, potassium_channel_antagonist: int, ppar_receptor_agonist: int, ppar_receptor_antagonist: int, progesterone_receptor_agonist: int, progesterone_receptor_antagonist: int, prostaglandin_inhibitor: int, prostanoid_receptor_antagonist: int, proteasome_inhibitor: int, protein_kinase_inhibitor: int, protein_phosphatase_inhibitor: int, protein_synthesis_inhibitor: int, protein_tyrosine_kinase_inhibitor: int, radiopaque_medium: int, raf_inhibitor: int, ras_gtpase_inhibitor: int, retinoid_receptor_agonist: int, retinoid_receptor_antagonist: int, rho_associated_kinase_inhibitor: int, ribonucleoside_reductase_inhibitor: int, rna_polymerase_inhibitor: int, serotonin_receptor_agonist: int, serotonin_receptor_antagonist: int, serotonin_reuptake_inhibitor: int, sigma_receptor_agonist: int, sigma_receptor_antagonist: int, smoothened_receptor_antagonist: int, sodium_channel_inhibitor: int, sphingosine_receptor_agonist: int, src_inhibitor: int, steroid: int, syk_inhibitor: int, tachykinin_antagonist: int, tgf-beta_receptor_inhibitor: int, thrombin_inhibitor: int, thymidylate_synthase_inhibitor: int, tlr_agonist: int, tlr_antagonist: int, tnf_inhibitor: int, topoisomerase_inhibitor: int, transient_receptor_potential_channel_antagonist: int, tropomyosin_receptor_kinase_inhibitor: int, trpv_agonist: int, trpv_antagonist: int, tubulin_inhibitor: int, tyrosine_kinase_inhibitor: int, ubiquitin_specific_protease_inhibitor: int, vegfr_inhibitor: int, vitamin_b: int, vitamin_d_receptor_agonist: int, wnt_inhibitor: int]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train test split\n",
    "(train, validation) = final_train.randomSplit([0.8, 0.2], 16)\n",
    "\n",
    "train.cache()\n",
    "validation.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e228a169-dea5-4254-8605-0f7baed953ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/206 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [05:39<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train finished with time: 339.50728964805603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train NaiveBayes\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, NaiveBayes\n",
    "import time\n",
    "labels = target_df.drop(sample_id).columns\n",
    "\n",
    "print('Start training')\n",
    "start = time.time()\n",
    "clf = MultiLabelClassifier(NaiveBayes, labels, 'features', hyperparameters={'modelType':'gaussian'}).fit(train)\n",
    "print('Train finished with time:', time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206it [01:20,  2.56it/s]\n",
      "3it [00:00, 21.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training prediction finished! time: 80.90630388259888\n",
      "Start validation prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206it [01:23,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation prediction finished! time: 84.10104489326477\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the NaiveBayes model\n",
    "print('Start training prediction')\n",
    "start = time.time()\n",
    "train_pred = clf.transform(train)\n",
    "print('Training prediction finished! time:', time.time() - start)\n",
    "\n",
    "\n",
    "print('Start validation prediction')\n",
    "start = time.time()\n",
    "validation_pred = clf.transform(validation)\n",
    "print('Validation prediction finished! time:', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|             score|\n",
      "+------------------+\n",
      "|15.863481433201864|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = target_df.select(*[sample_id]+labels)\n",
    "score(y, train_pred, sample_id).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/206 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/206 [00:12<41:35, 12.17s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 2/206 [00:22<39:32, 11.63s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▏         | 3/206 [00:33<38:15, 11.31s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 4/206 [00:43<37:35, 11.17s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 5/206 [00:55<37:21, 11.15s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 6/206 [01:05<36:45, 11.03s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 7/206 [01:16<36:39, 11.05s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▍         | 8/206 [01:27<35:58, 10.90s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▍         | 9/206 [01:38<35:30, 10.82s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|▉         | 19/206 [18:52:16<185:43:54, 3575.59s/it]\n",
      "  5%|▌         | 11/206 [17:52:37<316:54:46, 5850.70s/it]\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 11/206 [01:59<34:41, 10.67s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|▌         | 12/206 [02:08<33:21, 10.32s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|▋         | 13/206 [02:18<32:44, 10.18s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|▋         | 14/206 [02:28<32:19, 10.10s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|▋         | 15/206 [02:38<31:42,  9.96s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|▊         | 16/206 [02:48<31:40, 10.00s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|▊         | 17/206 [02:58<31:28,  9.99s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|▊         | 18/206 [03:08<31:28, 10.04s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|▉         | 19/206 [03:18<31:34, 10.13s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|▉         | 20/206 [03:28<31:27, 10.15s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|█         | 21/206 [03:38<31:16, 10.14s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|█         | 22/206 [03:49<31:09, 10.16s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|█         | 23/206 [03:59<31:24, 10.30s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|█▏        | 24/206 [04:09<31:10, 10.28s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|█▏        | 25/206 [04:20<31:03, 10.30s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█▎        | 26/206 [04:29<30:12, 10.07s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█▎        | 27/206 [04:39<29:52, 10.01s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 14%|█▎        | 28/206 [04:49<29:48, 10.05s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 14%|█▍        | 29/206 [05:00<30:03, 10.19s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█▍        | 30/206 [05:11<30:18, 10.33s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█▌        | 31/206 [05:21<29:58, 10.28s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|█▌        | 32/206 [05:32<30:32, 10.53s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|█▌        | 33/206 [05:43<31:02, 10.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|█▋        | 34/206 [05:53<30:26, 10.62s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|█▋        | 35/206 [06:03<29:29, 10.35s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|█▋        | 36/206 [06:13<29:20, 10.35s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|█▊        | 37/206 [06:24<29:35, 10.50s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|█▊        | 38/206 [06:35<29:21, 10.48s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|█▉        | 39/206 [06:46<29:27, 10.58s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|█▉        | 40/206 [06:57<29:53, 10.81s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|█▉        | 41/206 [07:08<30:16, 11.01s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|██        | 42/206 [07:19<29:41, 10.86s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|██        | 43/206 [07:31<30:23, 11.18s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|██▏       | 44/206 [07:41<29:31, 10.94s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|██▏       | 45/206 [07:53<30:08, 11.23s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|██▏       | 46/206 [08:04<29:37, 11.11s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|██▎       | 47/206 [08:14<28:48, 10.87s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|██▎       | 48/206 [08:25<28:10, 10.70s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|██▍       | 49/206 [08:35<27:49, 10.63s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|██▍       | 50/206 [08:46<27:30, 10.58s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|██▍       | 51/206 [08:56<27:16, 10.56s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|██▌       | 52/206 [09:07<27:04, 10.55s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|██▌       | 53/206 [09:17<26:45, 10.50s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|██▌       | 54/206 [09:28<26:50, 10.60s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██▋       | 55/206 [09:39<27:05, 10.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██▋       | 56/206 [09:50<27:08, 10.85s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|██▊       | 57/206 [10:00<26:38, 10.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|██▊       | 58/206 [10:11<26:28, 10.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|██▊       | 59/206 [10:22<26:14, 10.71s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|██▉       | 60/206 [10:32<25:31, 10.49s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|██▉       | 61/206 [10:42<25:15, 10.45s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|███       | 62/206 [10:52<24:35, 10.25s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███       | 63/206 [11:03<24:51, 10.43s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███       | 64/206 [11:13<24:35, 10.39s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|███▏      | 65/206 [11:24<24:41, 10.51s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|███▏      | 66/206 [11:35<24:47, 10.63s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|███▎      | 67/206 [11:45<24:25, 10.54s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|███▎      | 68/206 [11:56<24:12, 10.52s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|███▎      | 69/206 [12:06<23:51, 10.45s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|███▍      | 70/206 [12:16<23:24, 10.33s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|███▍      | 71/206 [12:26<22:46, 10.12s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|███▍      | 72/206 [12:36<22:40, 10.16s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|███▌      | 73/206 [12:45<22:10, 10.01s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|███▌      | 74/206 [12:55<21:57,  9.98s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|███▋      | 75/206 [13:06<21:57, 10.06s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 37%|███▋      | 76/206 [13:15<21:37,  9.98s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 37%|███▋      | 77/206 [13:25<21:10,  9.85s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|███▊      | 78/206 [13:35<21:26, 10.05s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|███▊      | 79/206 [13:46<21:25, 10.12s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|███▉      | 80/206 [13:56<21:32, 10.25s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|███▉      | 81/206 [14:07<21:43, 10.43s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|███▉      | 82/206 [14:20<23:03, 11.15s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 83/206 [14:31<22:44, 11.09s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|████      | 84/206 [14:41<22:07, 10.88s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|████▏     | 85/206 [14:52<21:39, 10.74s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████▏     | 86/206 [15:02<21:14, 10.62s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████▏     | 87/206 [15:13<21:06, 10.64s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████▎     | 88/206 [15:23<20:49, 10.59s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████▎     | 89/206 [15:34<20:38, 10.59s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 44%|████▎     | 90/206 [15:44<20:27, 10.58s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 44%|████▍     | 91/206 [15:55<20:26, 10.66s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|████▍     | 92/206 [16:07<20:47, 10.94s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|████▌     | 93/206 [16:17<20:18, 10.78s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|████▌     | 94/206 [16:28<19:54, 10.67s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|████▌     | 95/206 [16:38<19:27, 10.52s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|████▋     | 96/206 [16:48<19:00, 10.37s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|████▋     | 97/206 [16:58<18:29, 10.18s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|████▊     | 98/206 [17:07<17:56,  9.97s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|████▊     | 99/206 [17:17<17:53, 10.04s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|████▊     | 100/206 [17:28<17:56, 10.15s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|████▉     | 101/206 [17:39<18:24, 10.52s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|████▉     | 102/206 [17:50<18:12, 10.50s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████     | 103/206 [17:59<17:31, 10.20s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████     | 104/206 [18:09<17:11, 10.11s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 51%|█████     | 105/206 [18:19<16:49, 10.00s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 51%|█████▏    | 106/206 [18:29<16:43, 10.03s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|█████▏    | 107/206 [18:39<16:29, 10.00s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|█████▏    | 108/206 [18:48<16:08,  9.89s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|█████▎    | 109/206 [18:58<15:42,  9.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|█████▎    | 110/206 [19:07<15:36,  9.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|█████▍    | 111/206 [19:17<15:26,  9.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|█████▍    | 112/206 [19:27<15:21,  9.80s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████▍    | 113/206 [19:37<15:05,  9.74s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████▌    | 114/206 [19:47<15:07,  9.86s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████▌    | 115/206 [19:57<15:11, 10.02s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████▋    | 116/206 [20:08<15:12, 10.14s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████▋    | 117/206 [20:18<15:05, 10.18s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████▋    | 118/206 [20:28<14:44, 10.05s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|█████▊    | 119/206 [20:38<14:48, 10.21s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|█████▊    | 120/206 [20:48<14:28, 10.10s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|█████▊    | 121/206 [20:58<14:08,  9.98s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|█████▉    | 122/206 [21:08<13:52,  9.91s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|█████▉    | 123/206 [21:19<14:22, 10.39s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|██████    | 124/206 [21:31<14:47, 10.83s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|██████    | 125/206 [21:41<14:27, 10.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|██████    | 126/206 [21:53<14:35, 10.95s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 62%|██████▏   | 127/206 [22:04<14:22, 10.92s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 62%|██████▏   | 128/206 [22:13<13:43, 10.56s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 63%|██████▎   | 129/206 [22:23<13:19, 10.38s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 63%|██████▎   | 130/206 [22:33<12:55, 10.21s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 64%|██████▎   | 131/206 [22:43<12:37, 10.10s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 64%|██████▍   | 132/206 [22:53<12:24, 10.06s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|██████▍   | 133/206 [23:03<12:15, 10.08s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|██████▌   | 134/206 [23:14<12:15, 10.22s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|██████▌   | 135/206 [23:25<12:21, 10.44s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|██████▌   | 136/206 [23:36<12:22, 10.60s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████▋   | 137/206 [23:46<12:08, 10.56s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████▋   | 138/206 [23:56<11:47, 10.40s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████▋   | 139/206 [24:06<11:25, 10.24s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|██████▊   | 140/206 [24:17<11:22, 10.34s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|██████▊   | 141/206 [24:28<11:25, 10.54s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|██████▉   | 142/206 [24:39<11:28, 10.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|██████▉   | 143/206 [24:50<11:33, 11.01s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|██████▉   | 144/206 [25:02<11:39, 11.27s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|███████   | 145/206 [25:13<11:22, 11.18s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|███████   | 146/206 [25:24<11:00, 11.02s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|███████▏  | 147/206 [25:35<10:43, 10.90s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 72%|███████▏  | 148/206 [25:45<10:27, 10.82s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 72%|███████▏  | 149/206 [25:56<10:11, 10.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|███████▎  | 150/206 [26:06<09:57, 10.68s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|███████▎  | 151/206 [26:17<09:44, 10.63s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 74%|███████▍  | 152/206 [26:28<09:36, 10.67s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 74%|███████▍  | 153/206 [26:39<09:35, 10.85s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|███████▍  | 154/206 [26:50<09:25, 10.87s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 155/206 [27:00<09:09, 10.78s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 76%|███████▌  | 156/206 [27:12<09:05, 10.91s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 76%|███████▌  | 157/206 [27:23<09:07, 11.17s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|███████▋  | 158/206 [27:34<08:53, 11.11s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|███████▋  | 159/206 [27:46<08:57, 11.43s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|███████▊  | 160/206 [27:57<08:36, 11.23s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|███████▊  | 161/206 [28:07<08:09, 10.87s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|███████▊  | 162/206 [28:18<07:51, 10.71s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|███████▉  | 163/206 [28:27<07:29, 10.44s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|███████▉  | 164/206 [28:37<07:13, 10.32s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|████████  | 165/206 [28:47<06:59, 10.22s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|████████  | 166/206 [28:57<06:41, 10.03s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|████████  | 167/206 [29:07<06:25,  9.88s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|████████▏ | 168/206 [29:16<06:15,  9.87s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|████████▏ | 169/206 [29:26<06:07,  9.94s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|████████▎ | 170/206 [29:36<05:54,  9.84s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|████████▎ | 171/206 [29:46<05:42,  9.78s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|████████▎ | 172/206 [29:55<05:31,  9.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 84%|████████▍ | 173/206 [30:05<05:21,  9.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 84%|████████▍ | 174/206 [30:15<05:10,  9.71s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|████████▍ | 175/206 [30:25<05:02,  9.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|████████▌ | 176/206 [30:34<04:50,  9.68s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|████████▌ | 177/206 [30:44<04:42,  9.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|████████▋ | 178/206 [30:54<04:31,  9.71s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|████████▋ | 179/206 [31:04<04:23,  9.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|████████▋ | 180/206 [31:13<04:11,  9.68s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|████████▊ | 181/206 [31:23<04:03,  9.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|████████▊ | 182/206 [31:33<03:54,  9.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|████████▉ | 183/206 [31:43<03:45,  9.79s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|████████▉ | 184/206 [31:53<03:36,  9.84s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|████████▉ | 185/206 [32:02<03:24,  9.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|█████████ | 186/206 [32:12<03:14,  9.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|█████████ | 187/206 [32:21<03:04,  9.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|█████████▏| 188/206 [32:31<02:53,  9.66s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 92%|█████████▏| 189/206 [32:41<02:45,  9.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 92%|█████████▏| 190/206 [32:51<02:35,  9.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 93%|█████████▎| 191/206 [33:00<02:26,  9.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 93%|█████████▎| 192/206 [33:10<02:16,  9.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|█████████▎| 193/206 [33:20<02:06,  9.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|█████████▍| 194/206 [33:29<01:56,  9.67s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|█████████▍| 195/206 [33:39<01:46,  9.65s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|█████████▌| 196/206 [33:49<01:37,  9.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 96%|█████████▌| 197/206 [33:59<01:27,  9.71s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 96%|█████████▌| 198/206 [34:09<01:19,  9.95s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 97%|█████████▋| 199/206 [34:20<01:11, 10.19s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 97%|█████████▋| 200/206 [34:30<01:00, 10.09s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████▊| 201/206 [34:40<00:50, 10.11s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████▊| 202/206 [34:50<00:40, 10.06s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 99%|█████████▊| 203/206 [35:00<00:30, 10.04s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 99%|█████████▉| 204/206 [35:10<00:19,  9.99s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|█████████▉| 205/206 [35:20<00:09,  9.96s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 206/206 [35:30<00:00, 10.34s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train finished with time: 2130.5782680511475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree\n",
    "import time\n",
    "labels = target_df.drop(sample_id).columns\n",
    "\n",
    "print('Start training')\n",
    "start = time.time()\n",
    "clf = MultiLabelClassifier(DecisionTreeClassifier, labels, 'features').fit(train)\n",
    "print('Train finished with time:', time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206it [01:19,  2.58it/s]\n",
      "2it [00:00, 19.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training prediction finished! time: 80.20718717575073\n",
      "Start validation prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206it [01:16,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation prediction finished! time: 76.89807796478271\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the decision tree model\n",
    "print('Start training prediction')\n",
    "start = time.time()\n",
    "train_pred = clf.transform(train)\n",
    "print('Training prediction finished! time:', time.time() - start)\n",
    "\n",
    "\n",
    "print('Start validation prediction')\n",
    "start = time.time()\n",
    "validation_pred = clf.transform(validation)\n",
    "print('Validation prediction finished! time:', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               score|\n",
      "+--------------------+\n",
      "|0.013922339833575869|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = target_df.select(*[sample_id]+labels)\n",
    "score(y, train_pred, sample_id).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "project",
   "notebookOrigID": 3148343239384131,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
