{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import explode, col, udf, mean as _mean, stddev as _stddev, log, log10\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.functions import lit\n",
    "sc = SparkContext()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c7bc98a6-96a0-4899-9b1b-2686b17f1e7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, StandardScaler, VectorAssembler, VectorSlicer, PCA\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, NaiveBayes, LogisticRegression\n",
    "import time\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.ml.clustering import KMeans\n",
    "import re\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "02385597-27bc-418a-8725-873b1b3f2022",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Functions for Feature Engineering\n",
    "def encode_cat_features(df, cat_features):\n",
    "\n",
    "  indexed_cols = [''.join([col_name, '_indexed']) for col_name in cat_features]\n",
    "  encoded_cols = [''.join([col_name, '_encoded']) for col_name in cat_features]\n",
    "  string_indexers = [StringIndexer(inputCol=cat_features[i], outputCol=indexed_cols[i]) for i in range(len(cat_features))]\n",
    "    \n",
    "  encoder = OneHotEncoder(inputCols=indexed_cols, outputCols=encoded_cols)\n",
    "  \n",
    "  pipline = Pipeline(stages=string_indexers + [encoder])\n",
    "  \n",
    "  encoded_df = pipline.fit(df).transform(df)\n",
    "  encoded_df = encoded_df.drop(*indexed_cols + cat_features)\n",
    "\n",
    "  return encoded_df\n",
    "\n",
    "def normalize_features(df, cols, normalizer, output_cols, if_drop=True):\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  normalizer_lst = []\n",
    "  vectorized_cols = []\n",
    "  vector_assembers = []\n",
    "  \n",
    "  if isinstance(cols, list):\n",
    "    cols = {'cols': cols}\n",
    "  \n",
    "  if isinstance(output_cols, str):\n",
    "    output_cols = {'cols': output_cols}\n",
    "  \n",
    "  for k, v in cols.items():\n",
    "    \n",
    "    temp_normalizer = normalizer.copy()\n",
    "    vectorized_col = ''.join([output_cols[k], '_v'])\n",
    "    vector_assember = VectorAssembler(inputCols=v, outputCol=vectorized_col)\n",
    "    \n",
    "    temp_normalizer.setInputCol(vectorized_col)\n",
    "    temp_normalizer.setOutputCol(output_cols[k])\n",
    "    \n",
    "    normalizer_lst.append(temp_normalizer)\n",
    "    vectorized_cols.append(vectorized_col)\n",
    "    vector_assembers.append(vector_assember)\n",
    "  \n",
    "  pipline = Pipeline(stages=vector_assembers + normalizer_lst)\n",
    "  normalized_df = pipline.fit(df).transform(df).drop(*vectorized_cols)\n",
    "  \n",
    "  if if_drop:\n",
    "    \n",
    "    for k, v in cols.items():\n",
    "      \n",
    "      normalized_df = normalized_df.drop(v)\n",
    "  \n",
    "  return normalized_df\n",
    "\n",
    "def add_pca_features(df, g_cols, c_cols, k=40):\n",
    "  \n",
    "  ## normalize g-col and c-col\n",
    "  std_scaler = StandardScaler(withMean=True)\n",
    "  \n",
    "  input_cols = {\n",
    "    'g_cols': g_cols, \n",
    "    'c_cols': c_cols}\n",
    "  \n",
    "  output_cols = {\n",
    "    'g_cols': 'g_normalized', \n",
    "    'c_cols': 'c_normalized'}\n",
    "  \n",
    "  normalized_df = normalize_features(df, input_cols, std_scaler, output_cols, if_drop=False)\n",
    "  \n",
    "  ## perform PCA on g-cols and c-cols\n",
    "  g_col_pca = PCA(k=k, inputCol='g_normalized', outputCol='g_col_pca')\n",
    "  c_col_pca = PCA(k=k, inputCol='c_normalized', outputCol='c_col_pca')\n",
    "  \n",
    "  pipeline = Pipeline(stages=[g_col_pca, c_col_pca])\n",
    "  pca_df = pipeline.fit(normalized_df).transform(normalized_df)\n",
    "  \n",
    "  return pca_df\n",
    "  \n",
    "def add_stats_features(df, g_cols, c_cols):\n",
    "  \n",
    "  @udf('double')\n",
    "  def cols_sum(*lst):\n",
    "\n",
    "    return sum(lst)\n",
    "\n",
    "  @udf('double')\n",
    "  def cols_mean(*lst):\n",
    "\n",
    "    n = len(lst)\n",
    "    s = sum(lst)\n",
    "\n",
    "    return s / n\n",
    "\n",
    "  @udf('double')\n",
    "  def cols_var(*lst):\n",
    "\n",
    "    n = len(lst)\n",
    "    s = sum(lst) / n\n",
    "    total = 0\n",
    "\n",
    "    for x in lst:\n",
    "\n",
    "      total += (x - s)**2 \n",
    "\n",
    "    return total / n\n",
    "  \n",
    "  @udf('double')\n",
    "  def cols_min(*lst):\n",
    "    \n",
    "    return min(lst)\n",
    "  \n",
    "  @udf('double')\n",
    "  def cols_max(*lst):\n",
    "    \n",
    "    return max(lst)\n",
    "  \n",
    "  stats_dict = {\n",
    "    'min_stats': cols_min,\n",
    "    'max_stats': cols_max,\n",
    "    'var_stats': cols_var,\n",
    "    'mean_stats': cols_mean,\n",
    "    'sum_stats': cols_sum\n",
    "  }\n",
    "  \n",
    "  for name, func in stats_dict.items():\n",
    "    \n",
    "    df = df.withColumn(''.join(['g_cols_', name]), func(*[col(g_col) for g_col in g_cols]))\n",
    "    df = df.withColumn(''.join(['c_cols_', name]), func(*[col(c_col) for c_col in c_cols]))\n",
    "  \n",
    "  return df\n",
    "\n",
    "def add_kmeans_features(df, g_cols, c_cols, k=2, num_iter=10):\n",
    "  \n",
    "  kmeans_g = KMeans(k=k, featuresCol=g_cols, predictionCol='g_col_k_mean', seed=16)\n",
    "  kmeans_c = KMeans(k=k, featuresCol=c_cols, predictionCol='c_col_k_mean', seed=16)\n",
    "  \n",
    "  kmeans_df = kmeans_g.fit(df).transform(df)\n",
    "  kmeans_df = kmeans_c.fit(kmeans_df).transform(kmeans_df)\n",
    "  \n",
    "  return kmeans_df\n",
    "\n",
    "def feature_engineering(df, num_cluster=2, num_comp=40, num_iter=10):\n",
    "  \n",
    "  ## get g-col and c-col\n",
    "  g_cols = list(filter(lambda v: re.match('g-.+', v), df.columns))\n",
    "  c_cols = list(filter(lambda v: re.match('c-.+', v), df.columns))\n",
    "  \n",
    "  ## PCA\n",
    "  pca_df = add_pca_features(df, g_cols, c_cols, num_comp)\n",
    "\n",
    "  ## stats features on g and c cols\n",
    "  stats_df = add_stats_features(pca_df, g_cols, c_cols)\n",
    "  \n",
    "  ## add k-means features\n",
    "  kmeans_df = add_kmeans_features(stats_df, g_cols='g_normalized', c_cols='c_normalized', k=num_cluster, num_iter=num_iter)\n",
    "  \n",
    "  return kmeans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Multilabel Classifier\n",
    "class MultiLabelClassifier:\n",
    "    \n",
    "    def __init__(self, clf, labels, feature_col,  \n",
    "                 hyperparameters={}, \n",
    "                 predict_col=['probability','prediction'],\n",
    "                 method=lambda prob_col, pred_col: float(pred_col if len(prob_col) == 1 else prob_col[1])):\n",
    "        '''\n",
    "        Initialize a multilabelclassifier\n",
    "        clf: the model to use\n",
    "        labels: a list of labels to predict\n",
    "        feature_col: the feature column\n",
    "        predict_col: the prediction column where the prediction is located\n",
    "        hyperparameters: all optional hyperparameters that can tune\n",
    "        method: a method of how to get the final prediction for one class\n",
    "        '''\n",
    "        self.clf = clf\n",
    "        self.labels = labels\n",
    "        self.feature_col = feature_col\n",
    "        self.predict_col = predict_col\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.method = method\n",
    "        self._trained_clfs = []\n",
    "        self.res = None\n",
    "\n",
    "    def fit(self, train):\n",
    "        train.cache()\n",
    "        self._trained_clfs = [self.clf(labelCol=label, featuresCol=self.feature_col, **self.hyperparameters)\n",
    "                              .fit(train) \n",
    "                              for label in tqdm(self.labels)]\n",
    "        train.unpersist()\n",
    "        return self\n",
    "\n",
    "    def transform(self, x_test):\n",
    "        # convert method to udf\n",
    "        get_predict = udf(self.method,FloatType())\n",
    "        #target assembler\n",
    "        va = VectorAssembler(inputCols=self.labels, outputCol='targets')\n",
    "        ## transform this vector self.output_col to an array\n",
    "        select_cols = [self.feature_col, 'targets', 'sig_id']\n",
    "        res = va.transform(x_test).select(*select_cols)\n",
    "        for i, clf in tqdm(enumerate(self._trained_clfs)):\n",
    "            res = clf.transform(res)\n",
    "            new_col = self.labels[i]\n",
    "            res = res.withColumn(new_col, get_predict(*self.predict_col))\n",
    "            select_cols.append(new_col)\n",
    "            res = res.select(*select_cols)\n",
    "        self.res = res\n",
    "        return res.select(*select_cols[2:])\n",
    "    \n",
    "    def score(self):\n",
    "        #target assembler\n",
    "        va = VectorAssembler(inputCols=self.labels, outputCol='predicts')\n",
    "        ## transform this vector self.output_col to an array\n",
    "        df = va.transform(self.res).select('targets', 'predicts')\n",
    "        df = df.withColumn('targets', vector_to_array('targets'))\n",
    "        df = df.withColumn('predicts', vector_to_array('predicts'))\n",
    "        import math\n",
    "        @udf('double')\n",
    "        def log_loss(y, y_hat):\n",
    "            r = 0\n",
    "            cut = 1e-15\n",
    "            for t, p in zip(y, y_hat):\n",
    "                p = max(min(p, 1-cut),cut)\n",
    "                r += t * math.log(p) + (1 - t) * math.log(1 - p)\n",
    "            return r/len(y)\n",
    "        df = df.select(log_loss('targets','predicts').alias('log_loss'))\n",
    "        return df.select((-_mean(col('log_loss'))).alias('score'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Transformer\n",
    "class ProbTransformer(Transformer):\n",
    "    \n",
    "    def __init__(self, outputCol,\n",
    "                 dropCols=['rawPrediction','probability','prediction'],\n",
    "                 predict_col=['probability','prediction'],\n",
    "                 method=lambda prob_col, pred_col: float(pred_col if len(prob_col) == 1 else prob_col[1])):\n",
    "        self.outputCol = outputCol\n",
    "        self.dropCols = dropCols\n",
    "        self.predict_col = predict_col\n",
    "        self.method = method\n",
    "    \n",
    "    def transform(self, data):\n",
    "        get_predict = udf(self.method,FloatType())\n",
    "        return data.withColumn(self.outputCol, get_predict(*self.predict_col)).drop(*self.dropCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(model, train_data, test_data):\n",
    "    print('Start training')\n",
    "    start = time.time()\n",
    "    clf = model.fit(train_data)\n",
    "    print('Train finished with time:', time.time() - start)\n",
    "    \n",
    "    print('Start training prediction')\n",
    "    start = time.time()\n",
    "    train_pred = clf.transform(train_data)\n",
    "    print('Training prediction finished! time:', time.time() - start)\n",
    "\n",
    "    print('Start training scoring')\n",
    "    s = time.time()\n",
    "    clf.score().show()\n",
    "    print('Calculation finished with time:', time.time() - s)\n",
    "    \n",
    "    print('Start test prediction')\n",
    "    start = time.time()\n",
    "    validation_pred = clf.transform(test_data)\n",
    "    print('Validation prediction finished! time:', time.time() - start)\n",
    "\n",
    "    print('Start test scoring')\n",
    "    s = time.time()\n",
    "    clf.score().show()\n",
    "    print('Calculation finished with time:', time.time() - s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0722f2bf-4663-4034-8ad2-28be805d8c33",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#file_path = '/FileStore/tables/'\n",
    "file_path = './'\n",
    "sample_id = 'sig_id'\n",
    "train_df = spark.read.csv(file_path+'train_features.csv', header=True, inferSchema=True)\n",
    "target_df = spark.read.csv(file_path+'train_targets_scored.csv', header=True, inferSchema=True)\n",
    "train_drug_df = spark.read.csv(file_path+'train_drug.csv', header=True, inferSchema=True)\n",
    "target_nonscored_df = spark.read.csv(file_path+'train_targets_nonscored.csv', header=True, inferSchema=True)\n",
    "test_df = spark.read.csv(file_path+'test_features.csv', header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d7a98442-7ce1-4a03-afeb-28cf20d9c28b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## add indicator column to both train and test so we can combine them later\n",
    "train_df = train_df.withColumn('is_test', lit(0))\n",
    "test_df = test_df.withColumn('is_test', lit(1))\n",
    "\n",
    "## Combine train and test df\n",
    "full_df = train_df.union(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "00beab73-8c18-4835-b783-bede27b844ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## encode features\n",
    "target_cols = ['cp_type', 'cp_dose']\n",
    "encoded_df = encode_cat_features(full_df, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "55343a7f-035e-4f85-903f-5db6e44f50e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## feature engineering\n",
    "fe_df = feature_engineering(encoded_df, num_comp=20, num_iter=5)\n",
    "\n",
    "## select all the feature columns\n",
    "\n",
    "pca_cols = list(filter(lambda v: re.match('.+_pca', v), fe_df.columns))\n",
    "stats_cols = list(filter(lambda v: re.match('.+_stats', v), fe_df.columns))\n",
    "k_means_cols = list(filter(lambda v: re.match('.+_k_mean', v), fe_df.columns))\n",
    "cat_cols = list(filter(lambda v: re.match('.+_encoded', v), fe_df.columns)) + ['cp_time']\n",
    "\n",
    "## stack them to a single feature vector\n",
    "vector_assember_train = VectorAssembler(inputCols=pca_cols + stats_cols + k_means_cols + cat_cols, outputCol='all_features')\n",
    "fe_df = vector_assember_train.transform(fe_df)\n",
    "\n",
    "## normalize all the features\n",
    "normalizer = StandardScaler(withMean=True)\n",
    "cols = ['all_features']\n",
    "output_cols = 'features'\n",
    "fe_df = normalize_features(fe_df, cols, normalizer, output_cols, if_drop=False)\n",
    "\n",
    "## split train, test df\n",
    "fe_train = fe_df.filter(fe_df['is_test'] == 0)\n",
    "final_test = fe_df.filter(fe_df['is_test'] == 1).select(['sig_id', 'features'])\n",
    "\n",
    "## join training target with training features\n",
    "labels = target_df.drop('sig_id').columns\n",
    "final_train = fe_train.join(target_df, ['sig_id']).select(*(['sig_id','features']+labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bdf7e32a-ca3a-4de7-b522-31f1137d676c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## train test split\n",
    "(train, validation) = final_train.randomSplit([0.8, 0.2], 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import time\n",
    "s = time.time()\n",
    "# Cross Validation\n",
    "labels = target_df.drop(sample_id).columns\n",
    "label_probs = [label+'_prob' for label in labels]\n",
    "feature_col = 'features'\n",
    "hyperparameters = {'maxIter':10}\n",
    "clf = LogisticRegression\n",
    "\n",
    "stages = []\n",
    "for label in labels:\n",
    "    model = clf(labelCol=label, featuresCol=feature_col, **hyperparameters)\n",
    "    pipeline = Pipeline(stages=[model])\n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(model.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "    crossval = CrossValidator(estimator=pipeline,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=BinaryClassificationEvaluator(labelCol=label),\n",
    "                              numFolds=5,\n",
    "                              parallelism=5)  # use 3+ folds in practice\n",
    "    probTransformer = ProbTransformer(outputCol=label+'_prob')\n",
    "    stages.append(crossval)\n",
    "    stages.append(probTransformer)\n",
    "pipeline = Pipeline(stages=stages)\n",
    "model = pipeline.fit(train)\n",
    "prediction = model.transform(train)\n",
    "prediction.select(*[sample_id]+label_probs).show()\n",
    "print(time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e228a169-dea5-4254-8605-0f7baed953ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [06:00<00:00,  1.75s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train finished with time: 361.6467852592468\n",
      "Start training prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206it [01:25,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training prediction finished! time: 86.2536518573761\n",
      "Start training scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               score|\n",
      "+--------------------+\n",
      "|0.015354268249097913|\n",
      "+--------------------+\n",
      "\n",
      "Calculation finished with time: 40.25636100769043\n",
      "Start test prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206it [01:28,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation prediction finished! time: 89.02509927749634\n",
      "Start test scoring\n",
      "+------------------+\n",
      "|             score|\n",
      "+------------------+\n",
      "|0.0345501050800465|\n",
      "+------------------+\n",
      "\n",
      "Calculation finished with time: 18.61404776573181\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "labels = target_df.drop(sample_id).columns\n",
    "# DecisionTreeClassifier baseline\n",
    "model = MultiLabelClassifier(DecisionTreeClassifier, labels, 'features')\n",
    "baseline(model, train, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [22:57<00:00,  6.69s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train finished with time: 1377.9056544303894\n",
      "Start training prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206it [01:27,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training prediction finished! time: 87.99577140808105\n",
      "Start training scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               score|\n",
      "+--------------------+\n",
      "|0.014305106546989223|\n",
      "+--------------------+\n",
      "\n",
      "Calculation finished with time: 41.924421310424805\n",
      "Start test prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206it [02:43,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation prediction finished! time: 164.35324668884277\n",
      "Start test scoring\n",
      "+--------------------+\n",
      "|               score|\n",
      "+--------------------+\n",
      "|0.019969526627343505|\n",
      "+--------------------+\n",
      "\n",
      "Calculation finished with time: 28.378750562667847\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression baseline\n",
    "model = MultiLabelClassifier(LogisticRegression, labels, 'features')\n",
    "baseline(model, train, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [07:45<00:00,  2.26s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train finished with time: 466.04742336273193\n",
      "Start training prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206it [01:26,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training prediction finished! time: 86.83528208732605\n",
      "Start training scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               score|\n",
      "+--------------------+\n",
      "|0.020495972786880496|\n",
      "+--------------------+\n",
      "\n",
      "Calculation finished with time: 31.32410764694214\n",
      "Start test prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206it [01:25,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation prediction finished! time: 85.70474433898926\n",
      "Start test scoring\n",
      "+--------------------+\n",
      "|               score|\n",
      "+--------------------+\n",
      "|0.020215978410364932|\n",
      "+--------------------+\n",
      "\n",
      "Calculation finished with time: 18.266181230545044\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression baseline\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scalerModel = scaler.fit(final_train)\n",
    "scaledData = scalerModel.transform(final_train)\n",
    "(train, validation) = scaledData.randomSplit([0.8, 0.2], 16)\n",
    "\n",
    "hyperparameters = {'smoothing': 1,\n",
    "                  'modelType':\"multinomial\"}\n",
    "model = MultiLabelClassifier(NaiveBayes, labels, 'scaledFeatures')\n",
    "baseline(model, train, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "project",
   "notebookOrigID": 3148343239384131,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
