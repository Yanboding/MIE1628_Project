{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import explode, col, udf, mean as _mean, stddev as _stddev, log, log10\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.functions import lit\n",
    "#sc = SparkContext()\n",
    "#spark = SparkSession(sc)\n",
    "spark = SparkSession.builder.master('local[*]').config('spark.executor.memory','30g').appName('my-cool-app').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'30g'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get('spark.executor.memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c7bc98a6-96a0-4899-9b1b-2686b17f1e7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, StandardScaler, VectorAssembler, VectorSlicer, PCA\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, NaiveBayes, LogisticRegression\n",
    "import time\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.ml.clustering import KMeans\n",
    "import re\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "02385597-27bc-418a-8725-873b1b3f2022",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Functions for Feature Engineering\n",
    "def encode_cat_features(df, cat_features):\n",
    "\n",
    "  indexed_cols = [''.join([col_name, '_indexed']) for col_name in cat_features]\n",
    "  encoded_cols = [''.join([col_name, '_encoded']) for col_name in cat_features]\n",
    "  string_indexers = [StringIndexer(inputCol=cat_features[i], outputCol=indexed_cols[i]) for i in range(len(cat_features))]\n",
    "    \n",
    "  encoder = OneHotEncoder(inputCols=indexed_cols, outputCols=encoded_cols)\n",
    "  \n",
    "  pipline = Pipeline(stages=string_indexers + [encoder])\n",
    "  \n",
    "  encoded_df = pipline.fit(df).transform(df)\n",
    "  encoded_df = encoded_df.drop(*indexed_cols + cat_features)\n",
    "\n",
    "  return encoded_df\n",
    "\n",
    "def normalize_features(df, cols, normalizer, output_cols, if_drop=True):\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  normalizer_lst = []\n",
    "  vectorized_cols = []\n",
    "  vector_assembers = []\n",
    "  \n",
    "  if isinstance(cols, list):\n",
    "    cols = {'cols': cols}\n",
    "  \n",
    "  if isinstance(output_cols, str):\n",
    "    output_cols = {'cols': output_cols}\n",
    "  \n",
    "  for k, v in cols.items():\n",
    "    \n",
    "    temp_normalizer = normalizer.copy()\n",
    "    vectorized_col = ''.join([output_cols[k], '_v'])\n",
    "    vector_assember = VectorAssembler(inputCols=v, outputCol=vectorized_col)\n",
    "    \n",
    "    temp_normalizer.setInputCol(vectorized_col)\n",
    "    temp_normalizer.setOutputCol(output_cols[k])\n",
    "    \n",
    "    normalizer_lst.append(temp_normalizer)\n",
    "    vectorized_cols.append(vectorized_col)\n",
    "    vector_assembers.append(vector_assember)\n",
    "  \n",
    "  pipline = Pipeline(stages=vector_assembers + normalizer_lst)\n",
    "  normalized_df = pipline.fit(df).transform(df).drop(*vectorized_cols)\n",
    "  \n",
    "  if if_drop:\n",
    "    \n",
    "    for k, v in cols.items():\n",
    "      \n",
    "      normalized_df = normalized_df.drop(v)\n",
    "  \n",
    "  return normalized_df\n",
    "\n",
    "def add_pca_features(df, g_cols, c_cols, k=40):\n",
    "  \n",
    "  ## normalize g-col and c-col\n",
    "  std_scaler = StandardScaler(withMean=True)\n",
    "  \n",
    "  input_cols = {\n",
    "    'g_cols': g_cols, \n",
    "    'c_cols': c_cols}\n",
    "  \n",
    "  output_cols = {\n",
    "    'g_cols': 'g_normalized', \n",
    "    'c_cols': 'c_normalized'}\n",
    "  \n",
    "  normalized_df = normalize_features(df, input_cols, std_scaler, output_cols, if_drop=False)\n",
    "  \n",
    "  ## perform PCA on g-cols and c-cols\n",
    "  g_col_pca = PCA(k=k, inputCol='g_normalized', outputCol='g_col_pca')\n",
    "  c_col_pca = PCA(k=k, inputCol='c_normalized', outputCol='c_col_pca')\n",
    "  \n",
    "  pipeline = Pipeline(stages=[g_col_pca, c_col_pca])\n",
    "  pca_df = pipeline.fit(normalized_df).transform(normalized_df)\n",
    "  \n",
    "  return pca_df\n",
    "  \n",
    "def add_stats_features(df, g_cols, c_cols):\n",
    "  \n",
    "  @udf('double')\n",
    "  def cols_sum(*lst):\n",
    "\n",
    "    return sum(lst)\n",
    "\n",
    "  @udf('double')\n",
    "  def cols_mean(*lst):\n",
    "\n",
    "    n = len(lst)\n",
    "    s = sum(lst)\n",
    "\n",
    "    return s / n\n",
    "\n",
    "  @udf('double')\n",
    "  def cols_var(*lst):\n",
    "\n",
    "    n = len(lst)\n",
    "    s = sum(lst) / n\n",
    "    total = 0\n",
    "\n",
    "    for x in lst:\n",
    "\n",
    "      total += (x - s)**2 \n",
    "\n",
    "    return total / n\n",
    "  \n",
    "  @udf('double')\n",
    "  def cols_min(*lst):\n",
    "    \n",
    "    return min(lst)\n",
    "  \n",
    "  @udf('double')\n",
    "  def cols_max(*lst):\n",
    "    \n",
    "    return max(lst)\n",
    "  \n",
    "  stats_dict = {\n",
    "    'min_stats': cols_min,\n",
    "    'max_stats': cols_max,\n",
    "    'var_stats': cols_var,\n",
    "    'mean_stats': cols_mean,\n",
    "    'sum_stats': cols_sum\n",
    "  }\n",
    "  \n",
    "  for name, func in stats_dict.items():\n",
    "    \n",
    "    df = df.withColumn(''.join(['g_cols_', name]), func(*[col(g_col) for g_col in g_cols]))\n",
    "    df = df.withColumn(''.join(['c_cols_', name]), func(*[col(c_col) for c_col in c_cols]))\n",
    "  \n",
    "  return df\n",
    "\n",
    "def add_kmeans_features(df, g_cols, c_cols, k=2, num_iter=10):\n",
    "  \n",
    "  kmeans_g = KMeans(k=k, featuresCol=g_cols, predictionCol='g_col_k_mean', seed=16)\n",
    "  kmeans_c = KMeans(k=k, featuresCol=c_cols, predictionCol='c_col_k_mean', seed=16)\n",
    "  \n",
    "  kmeans_df = kmeans_g.fit(df).transform(df)\n",
    "  kmeans_df = kmeans_c.fit(kmeans_df).transform(kmeans_df)\n",
    "  \n",
    "  return kmeans_df\n",
    "\n",
    "def feature_engineering(df, num_cluster=2, num_comp=40, num_iter=10):\n",
    "  \n",
    "  ## get g-col and c-col\n",
    "  g_cols = list(filter(lambda v: re.match('g-.+', v), df.columns))\n",
    "  c_cols = list(filter(lambda v: re.match('c-.+', v), df.columns))\n",
    "  \n",
    "  ## PCA\n",
    "  pca_df = add_pca_features(df, g_cols, c_cols, num_comp)\n",
    "\n",
    "  ## stats features on g and c cols\n",
    "  stats_df = add_stats_features(pca_df, g_cols, c_cols)\n",
    "  \n",
    "  ## add k-means features\n",
    "  kmeans_df = add_kmeans_features(stats_df, g_cols='g_normalized', c_cols='c_normalized', k=num_cluster, num_iter=num_iter)\n",
    "  \n",
    "  return kmeans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Multilabel Classifier\n",
    "class MultiLabelClassifier:\n",
    "    \n",
    "    def __init__(self, clf, labels, feature_col,  \n",
    "                 hyperparameters={}, \n",
    "                 predict_col=['probability','prediction'],\n",
    "                 method=lambda prob_col, pred_col: float(pred_col if len(prob_col) == 1 else prob_col[1])):\n",
    "        '''\n",
    "        Initialize a multilabelclassifier\n",
    "        clf: the model to use\n",
    "        labels: a list of labels to predict\n",
    "        feature_col: the feature column\n",
    "        predict_col: the prediction column where the prediction is located\n",
    "        hyperparameters: all optional hyperparameters that can tune\n",
    "        method: a method of how to get the final prediction for one class\n",
    "        '''\n",
    "        self.clf = clf\n",
    "        self.labels = labels\n",
    "        self.feature_col = feature_col\n",
    "        self.predict_col = predict_col\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.method = method\n",
    "        self._trained_clfs = []\n",
    "        self.res = None\n",
    "\n",
    "    def fit(self, train):\n",
    "        train.cache()\n",
    "        self._trained_clfs = [self.clf(labelCol=label, featuresCol=self.feature_col, **self.hyperparameters)\n",
    "                              .fit(train) \n",
    "                              for label in tqdm(self.labels)]\n",
    "        train.unpersist()\n",
    "        return self\n",
    "\n",
    "    def transform(self, x_test):\n",
    "        # convert method to udf\n",
    "        get_predict = udf(self.method,FloatType())\n",
    "        #target assembler\n",
    "        va = VectorAssembler(inputCols=self.labels, outputCol='targets')\n",
    "        ## transform this vector self.output_col to an array\n",
    "        select_cols = [self.feature_col, 'targets', 'sig_id']\n",
    "        res = va.transform(x_test).select(*select_cols)\n",
    "        for i, clf in tqdm(enumerate(self._trained_clfs)):\n",
    "            res = clf.transform(res)\n",
    "            new_col = self.labels[i]\n",
    "            res = res.withColumn(new_col, get_predict(*self.predict_col))\n",
    "            select_cols.append(new_col)\n",
    "            res = res.select(*select_cols)\n",
    "        self.res = res\n",
    "        return res.select(*select_cols[2:])\n",
    "    \n",
    "    def score(self):\n",
    "        #target assembler\n",
    "        va = VectorAssembler(inputCols=self.labels, outputCol='predicts')\n",
    "        ## transform this vector self.output_col to an array\n",
    "        df = va.transform(self.res).select('targets', 'predicts')\n",
    "        df = df.withColumn('targets', vector_to_array('targets'))\n",
    "        df = df.withColumn('predicts', vector_to_array('predicts'))\n",
    "        import math\n",
    "        @udf('double')\n",
    "        def log_loss(y, y_hat):\n",
    "            r = 0\n",
    "            cut = 1e-15\n",
    "            for t, p in zip(y, y_hat):\n",
    "                p = max(min(p, 1-cut),cut)\n",
    "                r += t * math.log(p) + (1 - t) * math.log(1 - p)\n",
    "            return r/len(y)\n",
    "        df = df.select(log_loss('targets','predicts').alias('log_loss'))\n",
    "        return df.select((-_mean(col('log_loss'))).alias('score'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Transformer\n",
    "class ProbTransformer(Transformer):\n",
    "    \n",
    "    def __init__(self, outputCol,\n",
    "                 dropCols=['rawPrediction','probability','prediction'],\n",
    "                 predict_col=['probability','prediction'],\n",
    "                 method=lambda prob_col, pred_col: float(pred_col if len(prob_col) == 1 else prob_col[1])):\n",
    "        self.outputCol = outputCol\n",
    "        self.dropCols = dropCols\n",
    "        self.predict_col = predict_col\n",
    "        self.method = method\n",
    "    \n",
    "    def transform(self, data):\n",
    "        get_predict = udf(self.method,FloatType())\n",
    "        return data.withColumn(self.outputCol, get_predict(*self.predict_col)).drop(*self.dropCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import Evaluator\n",
    "class MultilabelEvaluator(Evaluator):\n",
    "    \n",
    "    def __init__(self, method=lambda prob_col, pred_col: float(pred_col if len(prob_col) == 1 else prob_col[1]), predictionCol=['probability', 'prediction'], labelCol=\"label\"):\n",
    "        \n",
    "        self.predictionCol = predictionCol\n",
    "        self.labelCol = labelCol\n",
    "        self.method = method\n",
    "        \n",
    "    def _evaluate(self, dataset):\n",
    "        \n",
    "        get_predict = udf(self.method,FloatType())\n",
    "        dataset = dataset.withColumn('pred_prob', get_predict(*self.predictionCol))\n",
    "        cut = 1e-15\n",
    "        new_dataset = dataset.select((-col(self.labelCol) * log(col('pred_prob') + cut) - (1.0 - col(self.labelCol)) * log(1.0 - col('pred_prob') + cut)).alias('log_loss'))        \n",
    "        score = new_dataset.select(_mean(col('log_loss')).alias('score')).collect()[0]['score']\n",
    "        return score\n",
    "        \n",
    "    def isLargerBetter(self):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(model, train_data, test_data):\n",
    "    print('Start training')\n",
    "    start = time.time()\n",
    "    clf = model.fit(train_data)\n",
    "    print('Train finished with time:', time.time() - start)\n",
    "    \n",
    "    print('Start training prediction')\n",
    "    start = time.time()\n",
    "    train_pred = clf.transform(train_data)\n",
    "    print('Training prediction finished! time:', time.time() - start)\n",
    "\n",
    "    print('Start training scoring')\n",
    "    s = time.time()\n",
    "    clf.score().show()\n",
    "    print('Calculation finished with time:', time.time() - s)\n",
    "    \n",
    "    print('Start test prediction')\n",
    "    start = time.time()\n",
    "    validation_pred = clf.transform(test_data)\n",
    "    print('Validation prediction finished! time:', time.time() - start)\n",
    "\n",
    "    print('Start test scoring')\n",
    "    s = time.time()\n",
    "    clf.score().show()\n",
    "    print('Calculation finished with time:', time.time() - s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0722f2bf-4663-4034-8ad2-28be805d8c33",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#file_path = '/FileStore/tables/'\n",
    "file_path = './'\n",
    "sample_id = 'sig_id'\n",
    "train_df = spark.read.csv(file_path+'train_features.csv', header=True, inferSchema=True)\n",
    "target_df = spark.read.csv(file_path+'train_targets_scored.csv', header=True, inferSchema=True)\n",
    "train_drug_df = spark.read.csv(file_path+'train_drug.csv', header=True, inferSchema=True)\n",
    "target_nonscored_df = spark.read.csv(file_path+'train_targets_nonscored.csv', header=True, inferSchema=True)\n",
    "test_df = spark.read.csv(file_path+'test_features.csv', header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d7a98442-7ce1-4a03-afeb-28cf20d9c28b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## add indicator column to both train and test so we can combine them later\n",
    "train_df = train_df.withColumn('is_test', lit(0))\n",
    "test_df = test_df.withColumn('is_test', lit(1))\n",
    "\n",
    "## Combine train and test df\n",
    "full_df = train_df.union(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "00beab73-8c18-4835-b783-bede27b844ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## encode features\n",
    "target_cols = ['cp_type', 'cp_dose']\n",
    "encoded_df = encode_cat_features(full_df, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "55343a7f-035e-4f85-903f-5db6e44f50e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## feature engineering\n",
    "fe_df = feature_engineering(encoded_df, num_comp=20, num_iter=5)\n",
    "\n",
    "## select all the feature columns\n",
    "\n",
    "pca_cols = list(filter(lambda v: re.match('.+_pca', v), fe_df.columns))\n",
    "stats_cols = list(filter(lambda v: re.match('.+_stats', v), fe_df.columns))\n",
    "k_means_cols = list(filter(lambda v: re.match('.+_k_mean', v), fe_df.columns))\n",
    "cat_cols = list(filter(lambda v: re.match('.+_encoded', v), fe_df.columns)) + ['cp_time']\n",
    "\n",
    "## stack them to a single feature vector\n",
    "vector_assember_train = VectorAssembler(inputCols=pca_cols + stats_cols + k_means_cols + cat_cols, outputCol='all_features')\n",
    "fe_df = vector_assember_train.transform(fe_df)\n",
    "\n",
    "## normalize all the features\n",
    "normalizer = StandardScaler(withMean=True)\n",
    "cols = ['all_features']\n",
    "output_cols = 'features'\n",
    "fe_df = normalize_features(fe_df, cols, normalizer, output_cols, if_drop=False)\n",
    "\n",
    "## split train, test df\n",
    "fe_train = fe_df.filter(fe_df['is_test'] == 0)\n",
    "final_test = fe_df.filter(fe_df['is_test'] == 1).select(['sig_id', 'features'])\n",
    "\n",
    "## join training target with training features\n",
    "labels = target_df.drop('sig_id').columns\n",
    "final_train = fe_train.join(target_df, ['sig_id']).select(*(['sig_id','features']+labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bdf7e32a-ca3a-4de7-b522-31f1137d676c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## train test split\n",
    "(train, validation) = final_train.randomSplit([0.8, 0.2], 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o133161.collectToPython.\n: org.apache.spark.SparkException: Job 4385 cancelled because SparkContext was shut down\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1(DAGScheduler.scala:979)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1$adapted(DAGScheduler.scala:977)\n\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:79)\n\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:977)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2257)\n\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2170)\n\tat org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:1973)\n\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)\n\tat org.apache.spark.SparkContext.stop(SparkContext.scala:1973)\n\tat org.apache.spark.SparkContext.$anonfun$new$35(SparkContext.scala:631)\n\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\n\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)\n\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\n\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\n\tat org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2120)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2139)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2164)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1003)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:385)\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3450)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3618)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3616)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3447)\n\tat jdk.internal.reflect.GeneratedMethodAccessor260.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-989667c4d5ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mstages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobTransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlabel_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.0.1-bin-hadoop2.7/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/spark-3.0.1-bin-hadoop2.7/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.0.1-bin-hadoop2.7/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/spark-3.0.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parallelFitTasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnFolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m                    \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.0.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parallelFitTasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnFolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.0.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36msingleTask\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msingleTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelIter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcollectSubModel\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.0.1-bin-hadoop2.7/python/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-8a3c09bb1f7a>\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mnew_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pred_prob'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcut\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pred_prob'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.0.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    594\u001b[0m         \"\"\"\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.0.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o133161.collectToPython.\n: org.apache.spark.SparkException: Job 4385 cancelled because SparkContext was shut down\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1(DAGScheduler.scala:979)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1$adapted(DAGScheduler.scala:977)\n\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:79)\n\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:977)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2257)\n\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2170)\n\tat org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:1973)\n\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)\n\tat org.apache.spark.SparkContext.stop(SparkContext.scala:1973)\n\tat org.apache.spark.SparkContext.$anonfun$new$35(SparkContext.scala:631)\n\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\n\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)\n\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\n\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\n\tat org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2120)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2139)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2164)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1003)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:385)\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3450)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3618)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3616)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3447)\n\tat jdk.internal.reflect.GeneratedMethodAccessor260.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nick/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1207, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nick/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1033, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/nick/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1211, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 61714)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nick/miniconda3/lib/python3.8/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/home/nick/miniconda3/lib/python3.8/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/home/nick/miniconda3/lib/python3.8/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/home/nick/miniconda3/lib/python3.8/socketserver.py\", line 720, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/nick/spark-3.0.1-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/nick/spark-3.0.1-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/nick/spark-3.0.1-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/nick/spark-3.0.1-bin-hadoop2.7/python/pyspark/serializers.py\", line 595, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import time\n",
    "\n",
    "s = time.time()\n",
    "# Cross Validation\n",
    "labels = target_df.drop(sample_id).columns\n",
    "train = train.select(*[sample_id, 'features']+labels)\n",
    "label_probs = [label+'_prob' for label in labels]\n",
    "feature_col = 'features'\n",
    "#hyperparameters = {'maxIter':10}\n",
    "hyperparameters = {}\n",
    "clf = DecisionTreeClassifier\n",
    "fold_num = 3\n",
    "\n",
    "stages = []\n",
    "for label in labels:\n",
    "    model = clf(labelCol=label, featuresCol=feature_col, **hyperparameters)\n",
    "    pipeline = Pipeline(stages=[model])\n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(model.maxDepth, [2, 5]) \\\n",
    "    .addGrid(model.impurity, ['gini', 'entropy']) \\\n",
    "    .build()\n",
    "    crossval = CrossValidator(estimator=pipeline,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=MultilabelEvaluator(labelCol=label),\n",
    "                              numFolds=2,\n",
    "                              parallelism=3)  # use 3+ folds in practice\n",
    "    probTransformer = ProbTransformer(outputCol=label+'_prob')\n",
    "    stages.append(crossval)\n",
    "    stages.append(probTransformer)\n",
    "pipeline = Pipeline(stages=stages)\n",
    "model = pipeline.fit(train)\n",
    "prediction = model.transform(train)\n",
    "prediction.select(*[sample_id]+label_probs).show()\n",
    "print(time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e228a169-dea5-4254-8605-0f7baed953ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 206/206 [06:00<00:00,  1.75s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train finished with time: 361.6467852592468\n",
      "Start training prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206it [01:25,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training prediction finished! time: 86.2536518573761\n",
      "Start training scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               score|\n",
      "+--------------------+\n",
      "|0.015354268249097913|\n",
      "+--------------------+\n",
      "\n",
      "Calculation finished with time: 40.25636100769043\n",
      "Start test prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206it [01:28,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation prediction finished! time: 89.02509927749634\n",
      "Start test scoring\n",
      "+------------------+\n",
      "|             score|\n",
      "+------------------+\n",
      "|0.0345501050800465|\n",
      "+------------------+\n",
      "\n",
      "Calculation finished with time: 18.61404776573181\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "labels = target_df.drop(sample_id).columns\n",
    "# DecisionTreeClassifier baseline\n",
    "model = MultiLabelClassifier(DecisionTreeClassifier, labels, 'features')\n",
    "baseline(model, train, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 206/206 [22:57<00:00,  6.69s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train finished with time: 1377.9056544303894\n",
      "Start training prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206it [01:27,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training prediction finished! time: 87.99577140808105\n",
      "Start training scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               score|\n",
      "+--------------------+\n",
      "|0.014305106546989223|\n",
      "+--------------------+\n",
      "\n",
      "Calculation finished with time: 41.924421310424805\n",
      "Start test prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206it [02:43,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation prediction finished! time: 164.35324668884277\n",
      "Start test scoring\n",
      "+--------------------+\n",
      "|               score|\n",
      "+--------------------+\n",
      "|0.019969526627343505|\n",
      "+--------------------+\n",
      "\n",
      "Calculation finished with time: 28.378750562667847\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression baseline\n",
    "model = MultiLabelClassifier(LogisticRegression, labels, 'features')\n",
    "baseline(model, train, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 206/206 [07:45<00:00,  2.26s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train finished with time: 466.04742336273193\n",
      "Start training prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206it [01:26,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training prediction finished! time: 86.83528208732605\n",
      "Start training scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               score|\n",
      "+--------------------+\n",
      "|0.020495972786880496|\n",
      "+--------------------+\n",
      "\n",
      "Calculation finished with time: 31.32410764694214\n",
      "Start test prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206it [01:25,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation prediction finished! time: 85.70474433898926\n",
      "Start test scoring\n",
      "+--------------------+\n",
      "|               score|\n",
      "+--------------------+\n",
      "|0.020215978410364932|\n",
      "+--------------------+\n",
      "\n",
      "Calculation finished with time: 18.266181230545044\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression baseline\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scalerModel = scaler.fit(final_train)\n",
    "scaledData = scalerModel.transform(final_train)\n",
    "(train, validation) = scaledData.randomSplit([0.8, 0.2], 16)\n",
    "\n",
    "hyperparameters = {'smoothing': 1,\n",
    "                  'modelType':\"multinomial\"}\n",
    "model = MultiLabelClassifier(NaiveBayes, labels, 'scaledFeatures')\n",
    "baseline(model, train, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './'\n",
    "sample_id = 'sig_id'\n",
    "train = spark.read.orc(file_path+'train')\n",
    "validation = spark.read.orc(file_path+'validation')\n",
    "target_df = spark.read.csv(file_path+'train_targets_scored.csv', header=True, inferSchema=True)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "project",
   "notebookOrigID": 3148343239384131,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
