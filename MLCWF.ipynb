{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import explode, col, udf, mean as _mean, stddev as _stddev, log, log10\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.functions import lit\n",
    "sc = SparkContext()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+------+------+\n",
      "| id|            text|label1|label2|\n",
      "+---+----------------+------+------+\n",
      "|  0| a b c d e spark|   1.0|   0.0|\n",
      "|  1|             b d|   0.0|   1.0|\n",
      "|  2|     spark f g h|   1.0|   0.0|\n",
      "|  3|hadoop mapreduce|   0.0|   1.0|\n",
      "|  4|     b spark who|   1.0|   0.0|\n",
      "|  5|         g d a y|   0.0|   1.0|\n",
      "|  6|       spark fly|   1.0|   0.0|\n",
      "|  7|   was mapreduce|   0.0|   1.0|\n",
      "|  8| e spark program|   1.0|   0.0|\n",
      "|  9|         a e c l|   0.0|   1.0|\n",
      "| 10|   spark compile|   1.0|   0.0|\n",
      "| 11| hadoop software|   0.0|   1.0|\n",
      "+---+----------------+------+------+\n",
      "\n",
      "+---+---------------+\n",
      "| id|           text|\n",
      "+---+---------------+\n",
      "|  4|    spark i j k|\n",
      "|  5|          l m n|\n",
      "|  6|mapreduce spark|\n",
      "|  7|  apache hadoop|\n",
      "+---+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare training documents, which are labeled.\n",
    "training = spark.createDataFrame([\n",
    "    (0, \"a b c d e spark\", 1.0, 0.0),\n",
    "    (1, \"b d\", 0.0, 1.0),\n",
    "    (2, \"spark f g h\", 1.0, 0.0),\n",
    "    (3, \"hadoop mapreduce\", 0.0, 1.0),\n",
    "    (4, \"b spark who\", 1.0, 0.0),\n",
    "    (5, \"g d a y\", 0.0, 1.0),\n",
    "    (6, \"spark fly\", 1.0, 0.0),\n",
    "    (7, \"was mapreduce\", 0.0, 1.0),\n",
    "    (8, \"e spark program\", 1.0, 0.0),\n",
    "    (9, \"a e c l\", 0.0, 1.0),\n",
    "    (10, \"spark compile\", 1.0, 0.0),\n",
    "    (11, \"hadoop software\", 0.0, 1.0)\n",
    "], [\"id\", \"text\", \"label1\", \"label2\"])\n",
    "\n",
    "# Prepare test documents, which are unlabeled.\n",
    "test = spark.createDataFrame([\n",
    "    (4, \"spark i j k\"),\n",
    "    (5, \"l m n\"),\n",
    "    (6, \"mapreduce spark\"),\n",
    "    (7, \"apache hadoop\")\n",
    "], [\"id\", \"text\"])\n",
    "training.show()\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Transformer\n",
    "class ProbTransformer(Transformer):\n",
    "    \n",
    "    def __init__(self, outputCol,\n",
    "                 dropCols=['rawPrediction','probability','prediction'],\n",
    "                 predict_col=['probability','prediction'],\n",
    "                 method=lambda prob_col, pred_col: float(pred_col if len(prob_col) == 1 else prob_col[1])):\n",
    "        self.outputCol = outputCol\n",
    "        self.dropCols = dropCols\n",
    "        self.predict_col = predict_col\n",
    "        self.method = method\n",
    "    \n",
    "    def transform(self, data):\n",
    "        get_predict = udf(self.method,FloatType())\n",
    "        return data.withColumn(self.outputCol, get_predict(*self.predict_col)).drop(*self.dropCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+------+------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "| id|            text|label1|label2|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+---+----------------+------+------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  0| a b c d e spark|   1.0|   0.0|[a, b, c, d, e, s...|(262144,[74920,89...|[-6.6901128719233...|[0.00124159896478...|       1.0|\n",
      "|  1|             b d|   0.0|   1.0|              [b, d]|(262144,[89530,14...|[6.22897857647562...|[0.99803241445632...|       0.0|\n",
      "|  2|     spark f g h|   1.0|   0.0|    [spark, f, g, h]|(262144,[36803,17...|[-9.0835373227814...|[1.13506456672275...|       1.0|\n",
      "|  3|hadoop mapreduce|   0.0|   1.0| [hadoop, mapreduce]|(262144,[132966,1...|[8.94924347957775...|[0.99987018150903...|       0.0|\n",
      "|  4|     b spark who|   1.0|   0.0|     [b, spark, who]|(262144,[143741,1...|[-8.5316022167572...|[1.97100001501920...|       1.0|\n",
      "|  5|         g d a y|   0.0|   1.0|        [g, d, a, y]|(262144,[36803,89...|[9.16910281088949...|[0.99989580089473...|       0.0|\n",
      "|  6|       spark fly|   1.0|   0.0|        [spark, fly]|(262144,[39928,17...|[-8.9473348944445...|[1.30066464943114...|       1.0|\n",
      "|  7|   was mapreduce|   0.0|   1.0|    [was, mapreduce]|(262144,[99211,13...|[8.75972857385371...|[0.99984309742533...|       0.0|\n",
      "|  8| e spark program|   1.0|   0.0| [e, spark, program]|(262144,[76285,16...|[-10.354302371990...|[3.18544258338441...|       1.0|\n",
      "|  9|         a e c l|   0.0|   1.0|        [a, e, c, l]|(262144,[1303,749...|[7.29297695624590...|[0.99932016268071...|       0.0|\n",
      "| 10|   spark compile|   1.0|   0.0|    [spark, compile]|(262144,[109869,1...|[-8.9473348944445...|[1.30066464943114...|       1.0|\n",
      "| 11| hadoop software|   0.0|   1.0|  [hadoop, software]|(262144,[123474,1...|[8.75972857385371...|[0.99984309742533...|       0.0|\n",
      "+---+----------------+------+------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n",
      "Row(id=4, text='spark i j k', probability=DenseVector([0.2661, 0.7339]), prediction=1.0)\n",
      "Row(id=5, text='l m n', probability=DenseVector([0.9209, 0.0791]), prediction=0.0)\n",
      "Row(id=6, text='mapreduce spark', probability=DenseVector([0.4429, 0.5571]), prediction=1.0)\n",
      "Row(id=7, text='apache hadoop', probability=DenseVector([0.8584, 0.1416]), prediction=0.0)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(labelCol='label1', featuresCol='features',maxIter=10)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n",
    "pipeline.fit(training).transform(training).show()\n",
    "# We now treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "# This will allow us to jointly choose parameters for all Pipeline stages.\n",
    "# A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "# With 3 values for hashingTF.numFeatures and 2 values for lr.regParam,\n",
    "# this grid will have 3 x 2 = 6 parameter settings for CrossValidator to choose from.\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(hashingTF.numFeatures, [10, 100, 1000]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(labelCol='label1'),\n",
    "                          numFolds=2)  # use 3+ folds in practice\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.fit(training)\n",
    "\n",
    "# Prepare test documents, which are unlabeled.\n",
    "test = spark.createDataFrame([\n",
    "    (4, \"spark i j k\"),\n",
    "    (5, \"l m n\"),\n",
    "    (6, \"mapreduce spark\"),\n",
    "    (7, \"apache hadoop\")\n",
    "], [\"id\", \"text\"])\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction = cvModel.transform(test)\n",
    "selected = prediction.select(\"id\", \"text\", \"probability\", \"prediction\")\n",
    "for row in selected.collect():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------+------+\n",
      "| id|            features|label1|label2|\n",
      "+---+--------------------+------+------+\n",
      "|  0|(262144,[74920,89...|   1.0|   0.0|\n",
      "|  1|(262144,[89530,14...|   0.0|   1.0|\n",
      "|  2|(262144,[36803,17...|   1.0|   0.0|\n",
      "|  3|(262144,[132966,1...|   0.0|   1.0|\n",
      "|  4|(262144,[143741,1...|   1.0|   0.0|\n",
      "|  5|(262144,[36803,89...|   0.0|   1.0|\n",
      "|  6|(262144,[39928,17...|   1.0|   0.0|\n",
      "|  7|(262144,[99211,13...|   0.0|   1.0|\n",
      "|  8|(262144,[76285,16...|   1.0|   0.0|\n",
      "|  9|(262144,[1303,749...|   0.0|   1.0|\n",
      "| 10|(262144,[109869,1...|   1.0|   0.0|\n",
      "| 11|(262144,[123474,1...|   0.0|   1.0|\n",
      "+---+--------------------+------+------+\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PipelineModel' object has no attribute 'regParam'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-bb271e70507c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# this grid will have 3 x 2 = 6 parameter settings for CrossValidator to choose from.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mparamGrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParamGridBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;34m.\u001b[0m\u001b[0maddGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregParam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mstages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PipelineModel' object has no attribute 'regParam'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "'''\n",
    "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and lr.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "labels = ['label1','label2']\n",
    "feature_col = 'features'\n",
    "hyperparameters = {'maxIter':10}\n",
    "clf = LogisticRegression\n",
    "mlc = []\n",
    "for label in labels:\n",
    "    mlc.append(clf(labelCol=label, featuresCol=feature_col, **hyperparameters))\n",
    "    mlc.append(ProbTransformer(outputCol=label+'_prob'))\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF]+mlc)\n",
    "model = pipeline.fit(training)\n",
    "prediction = model.transform(training)\n",
    "prediction.show()\n",
    "'''\n",
    "labels = ['label1','label2']\n",
    "feature_col = 'features'\n",
    "hyperparameters = {'maxIter':10}\n",
    "clf = LogisticRegression\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=feature_col)\n",
    "feature_eng_pipe = Pipeline(stages=[tokenizer, hashingTF])\n",
    "X = tokenizer.transform(training)\n",
    "X = hashingTF.transform(X)\n",
    "X = X.select(*['id','features','label1','label2'])\n",
    "X.show()\n",
    "# We now treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "# This will allow us to jointly choose parameters for all Pipeline stages.\n",
    "# A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "# With 3 values for hashingTF.numFeatures and 2 values for lr.regParam,\n",
    "# this grid will have 3 x 2 = 6 parameter settings for CrossValidator to choose from.\n",
    "\n",
    "stages = []\n",
    "for label in labels:\n",
    "    model = clf(labelCol=label, featuresCol=feature_col, **hyperparameters)\n",
    "    pipeline = Pipeline(stages=[model])\n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(model.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "    crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(labelCol=label),\n",
    "                          numFolds=2)  # use 3+ folds in practice\n",
    "    probTransformer = ProbTransformer(outputCol=label+'_prob')\n",
    "    stages.append(crossval)\n",
    "    stages.append(probTransformer)\n",
    "pipeline = Pipeline(stages=stages)\n",
    "model = pipeline.fit(X)\n",
    "prediction = model.transform(X)\n",
    "prediction.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pyspark.ml import Estimator\n",
    "from pyspark.ml import Pipeline\n",
    "# Multilabel Classifier\n",
    "class MultiLabelClassifier(Estimator):\n",
    "    \n",
    "    def __init__(self, clf, labels, feature_col,   \n",
    "                 predict_col=['probability','prediction'],\n",
    "                 method=lambda prob_col, pred_col: float(pred_col if len(prob_col) == 1 else prob_col[1]), \\\n",
    "                **hyperparameters):\n",
    "        '''\n",
    "        Initialize a multilabelclassifier\n",
    "        clf: the model to use\n",
    "        labels: a list of labels to predict\n",
    "        feature_col: the feature column\n",
    "        predict_col: the prediction column where the prediction is located\n",
    "        hyperparameters: all optional hyperparameters that can tune\n",
    "        method: a method of how to get the final prediction for one class\n",
    "        '''\n",
    "        self.clf = clf\n",
    "        self.labels = labels\n",
    "        self.feature_col = feature_col\n",
    "        self.predict_col = predict_col\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.method = method\n",
    "        \n",
    "        self._trained_clfs = Pipeline(stages=[clf(labelCol=label, featuresCol=feature_col, **self.hyperparameters)\n",
    "                                             for label in labels])\n",
    "        self.res = None\n",
    "\n",
    "    def fit(self, train):\n",
    "        self._trained_clfs = self._trained_clfs.fit(train)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, test):\n",
    "        #target assembler\n",
    "        va = VectorAssembler(inputCols=self.labels, outputCol='targets')\n",
    "        ## transform this vector self.output_col to an array\n",
    "        select_cols = [self.feature_col, 'targets', 'sig_id']\n",
    "        res = va.transform(x_test).select(*select_cols)\n",
    "        res = self._trained_clfs.transform(res)\n",
    "        return res\n",
    "    '''\n",
    "    def transform(self, x_test):\n",
    "        # convert method to udf\n",
    "        get_predict = udf(self.method,FloatType())\n",
    "        #target assembler\n",
    "        va = VectorAssembler(inputCols=self.labels, outputCol='targets')\n",
    "        ## transform this vector self.output_col to an array\n",
    "        select_cols = [self.feature_col, 'targets', 'sig_id']\n",
    "        res = va.transform(x_test).select(*select_cols)\n",
    "        for i, clf in tqdm(enumerate(self._trained_clfs)):\n",
    "            res = clf.transform(res)\n",
    "            new_col = self.labels[i]\n",
    "            res = res.withColumn(new_col, get_predict(*self.predict_col))\n",
    "            select_cols.append(new_col)\n",
    "            res = res.select(*select_cols)\n",
    "        self.res = res\n",
    "        return res.select(*select_cols[2:])\n",
    "    '''\n",
    "    def score(self):\n",
    "        #target assembler\n",
    "        va = VectorAssembler(inputCols=self.labels, outputCol='predicts')\n",
    "        ## transform this vector self.output_col to an array\n",
    "        df = va.transform(self.res).select('targets', 'predicts')\n",
    "        df = df.withColumn('targets', vector_to_array('targets'))\n",
    "        df = df.withColumn('predicts', vector_to_array('predicts'))\n",
    "        import math\n",
    "        @udf('double')\n",
    "        def log_loss(y, y_hat):\n",
    "            r = 0\n",
    "            cut = 1e-15\n",
    "            for t, p in zip(y, y_hat):\n",
    "                p = max(min(p, 1-cut),cut)\n",
    "                r += t * math.log(p) + (1 - t) * math.log(1 - p)\n",
    "            return r/len(y)\n",
    "        df = df.select(log_loss('targets','predicts').alias('log_loss'))\n",
    "        return df.select((-_mean(col('log_loss'))).alias('score'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
